<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Iterative Methoden | Numerik des Maschinellen Lernens</title>
  <meta name="description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Iterative Methoden | Numerik des Maschinellen Lernens" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  <meta name="github-repo" content="highlando/script-ndml" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Iterative Methoden | Numerik des Maschinellen Lernens" />
  
  <meta name="twitter:description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  

<meta name="author" content="Jan Heiland" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="fehler-und-konditionierung.html"/>
<link rel="next" href="stochastisches-gradientenverfahren.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">NdML</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="chapter" data-level="1" data-path="einführung.html"><a href="einführung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a>
<ul>
<li class="chapter" data-level="1.1" data-path="einführung.html"><a href="einführung.html#was-ist-ein-algorithmus"><i class="fa fa-check"></i><b>1.1</b> Was ist ein Algorithmus</a></li>
<li class="chapter" data-level="1.2" data-path="einführung.html"><a href="einführung.html#konsistenz-stabilität-genauigkeit"><i class="fa fa-check"></i><b>1.2</b> Konsistenz, Stabilität, Genauigkeit</a></li>
<li class="chapter" data-level="1.3" data-path="einführung.html"><a href="einführung.html#rechenkomplexität"><i class="fa fa-check"></i><b>1.3</b> Rechenkomplexität</a></li>
<li class="chapter" data-level="1.4" data-path="einführung.html"><a href="einführung.html#literatur"><i class="fa fa-check"></i><b>1.4</b> Literatur</a></li>
<li class="chapter" data-level="1.5" data-path="einführung.html"><a href="einführung.html#übungen"><i class="fa fa-check"></i><b>1.5</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html"><i class="fa fa-check"></i><b>2</b> Fehler und Konditionierung</a>
<ul>
<li class="chapter" data-level="2.1" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#fehler"><i class="fa fa-check"></i><b>2.1</b> Fehler</a></li>
<li class="chapter" data-level="2.2" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#kondition"><i class="fa fa-check"></i><b>2.2</b> Kondition</a></li>
<li class="chapter" data-level="2.3" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#kondition-der-grundrechenarten"><i class="fa fa-check"></i><b>2.3</b> Kondition der Grundrechenarten</a></li>
<li class="chapter" data-level="2.4" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#übungen-1"><i class="fa fa-check"></i><b>2.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="iterative-methoden.html"><a href="iterative-methoden.html"><i class="fa fa-check"></i><b>3</b> Iterative Methoden</a>
<ul>
<li class="chapter" data-level="3.1" data-path="iterative-methoden.html"><a href="iterative-methoden.html#iterative-methoden-als-fixpunktiteration"><i class="fa fa-check"></i><b>3.1</b> Iterative Methoden als Fixpunktiteration</a></li>
<li class="chapter" data-level="3.2" data-path="iterative-methoden.html"><a href="iterative-methoden.html#gradientenabstiegsverfahren"><i class="fa fa-check"></i><b>3.2</b> Gradientenabstiegsverfahren</a></li>
<li class="chapter" data-level="3.3" data-path="iterative-methoden.html"><a href="iterative-methoden.html#auxiliary-function-methods"><i class="fa fa-check"></i><b>3.3</b> Auxiliary Function Methods</a></li>
<li class="chapter" data-level="3.4" data-path="iterative-methoden.html"><a href="iterative-methoden.html#übungen-2"><i class="fa fa-check"></i><b>3.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html"><i class="fa fa-check"></i><b>4</b> Stochastisches Gradientenverfahren</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#motivation-und-algorithmus"><i class="fa fa-check"></i><b>4.1</b> Motivation und Algorithmus</a></li>
<li class="chapter" data-level="4.2" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#iterative_method"><i class="fa fa-check"></i><b>4.2</b> Stochastisches Abstiegsverfahren</a></li>
<li class="chapter" data-level="4.3" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#konvergenzanalyse"><i class="fa fa-check"></i><b>4.3</b> Konvergenzanalyse</a></li>
<li class="chapter" data-level="4.4" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#übungen-3"><i class="fa fa-check"></i><b>4.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html"><i class="fa fa-check"></i><b>5</b> Ein NN Beispiel</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#der-penguins-datensatz"><i class="fa fa-check"></i><b>5.1</b> Der PENGUINS Datensatz</a></li>
<li class="chapter" data-level="5.2" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#ein-2-layer-neuronales-netz-zur-klassifizierung"><i class="fa fa-check"></i><b>5.2</b> Ein <em>2</em>-Layer Neuronales Netz zur Klassifizierung</a></li>
<li class="chapter" data-level="5.3" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#beispiel-implementierung"><i class="fa fa-check"></i><b>5.3</b> Beispiel Implementierung</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html"><i class="fa fa-check"></i><b>6</b> Singulärwert Zerlegung</a>
<ul>
<li class="chapter" data-level="6.1" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#definition-und-eigenschaften"><i class="fa fa-check"></i><b>6.1</b> Definition und Eigenschaften</a></li>
<li class="chapter" data-level="6.2" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#numerische-berechnung"><i class="fa fa-check"></i><b>6.2</b> Numerische Berechnung</a></li>
<li class="chapter" data-level="6.3" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#aufgaben"><i class="fa fa-check"></i><b>6.3</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html"><i class="fa fa-check"></i><b>7</b> PCA und weitere SVD Anwendungen</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#proper-orthogonal-decomposition-pod"><i class="fa fa-check"></i><b>7.1</b> Proper-Orthogonal Decomposition – POD</a></li>
<li class="chapter" data-level="7.2" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#simultane-diagonalisierung"><i class="fa fa-check"></i><b>7.2</b> Simultane Diagonalisierung</a></li>
<li class="chapter" data-level="7.3" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#pca"><i class="fa fa-check"></i><b>7.3</b> PCA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>8</b> Support Vector Machines</a>
<ul>
<li class="chapter" data-level="8.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#problemstellung"><i class="fa fa-check"></i><b>8.1</b> Problemstellung</a></li>
<li class="chapter" data-level="8.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#maximierung-des-minimalen-abstands"><i class="fa fa-check"></i><b>8.2</b> Maximierung des Minimalen Abstands</a></li>
<li class="chapter" data-level="8.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#aufgaben-1"><i class="fa fa-check"></i><b>8.3</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html"><i class="fa fa-check"></i><b>9</b> Best and Universal Approximation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html#universal-approximation"><i class="fa fa-check"></i><b>9.1</b> Universal Approximation</a></li>
<li class="chapter" data-level="9.2" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html#aufgaben-2"><i class="fa fa-check"></i><b>9.2</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html"><i class="fa fa-check"></i><b>10</b> Automatisches (Algorithmisches) Differenzieren</a>
<ul>
<li class="chapter" data-level="10.1" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#andere-differentiationsmethoden"><i class="fa fa-check"></i><b>10.1</b> Andere Differentiationsmethoden</a></li>
<li class="chapter" data-level="10.2" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#anwendungen"><i class="fa fa-check"></i><b>10.2</b> Anwendungen</a></li>
<li class="chapter" data-level="10.3" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#vorwärts--und-rückwärtsakkumulation"><i class="fa fa-check"></i><b>10.3</b> Vorwärts- und Rückwärtsakkumulation</a></li>
<li class="chapter" data-level="10.4" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#ad-vorwärtsmodus"><i class="fa fa-check"></i><b>10.4</b> AD – Vorwärtsmodus</a></li>
<li class="chapter" data-level="10.5" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#rückwärtsmodus"><i class="fa fa-check"></i><b>10.5</b> Rückwärtsmodus</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html"><i class="fa fa-check"></i><b>11</b> Implementierungen, Anwendungsbeispiele, Backpropagation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#exkurs-gradienten-und-repräsentation"><i class="fa fa-check"></i><b>11.1</b> Exkurs – Gradienten und Repräsentation</a></li>
<li class="chapter" data-level="11.2" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#backpropagation"><i class="fa fa-check"></i><b>11.2</b> Backpropagation</a></li>
<li class="chapter" data-level="11.3" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#aufgaben-3"><i class="fa fa-check"></i><b>11.3</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="nachklapp.html"><a href="nachklapp.html"><i class="fa fa-check"></i><b>12</b> Nachklapp</a></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Numerik des Maschinellen Lernens</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="iterative-methoden" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Iterative Methoden<a href="iterative-methoden.html#iterative-methoden" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Allgemein nennen wir ein Verfahren, das sukzessive (also <em>iterativ</em>) eine Lösung <span class="math inline">\(z\)</span> über eine iterativ definierte Folge <span class="math inline">\(x_{k+1}=\phi_k(x_k)\)</span> annähert ein <em>iteratives Verfahren</em>.</p>
<p>Hierbei können <span class="math inline">\(z\)</span>, <span class="math inline">\(x_k\)</span>, <span class="math inline">\(x_{k+1}\)</span> skalare, Vektoren oder auch unendlich dimensionale Objekte sein und <span class="math inline">\(\phi_k\)</span> ist die Verfahrensfunktion, die das Verfahren beschreibt.
Oftmals ist das Verfahren immer das gleiche egal bei welchem Schritt <span class="math inline">\(k\)</span> Jan gerade ist, weshalb auch oft einfach <span class="math inline">\(\phi\)</span> geschrieben wird.</p>
<p>Bekannte Beispiele sind iterative Verfahren zur</p>
<ul>
<li>Lösung linearer Gleichungssysteme (z.B. <em>Gauss-Seidel</em>)</li>
<li>Lösung nichtlinearer Gleichungssysteme (z.B. <em>Newton</em>)</li>
<li>Optimierung (z.B. von ML Modellen mittels <em>Gradientenabstieg</em>)</li>
</ul>
<p>Der Einfachheit halber betrachten wir zunächst <span class="math inline">\(z\)</span>, <span class="math inline">\(x_k\)</span>, <span class="math inline">\(x_{k+1}\in \mathbb R^{}\)</span>.
Die Erweiterung der Definitionen erfolgt dann über die Formulierung mit Hilfe passender Normen anstelle des Betrags.</p>
<div class="definition">
<p><span id="def:iterative-convergence" class="definition"><strong>Definition 3.1  (Konvergenz einer Iteration) </strong></span>Eine Iteration die eine Folge <span class="math inline">\((x_k)_{k\in \mathbb N^{}}\subset \mathbb R^{}\)</span> produziert, heißt <em>konvergent der Ordnung <span class="math inline">\(p\)</span></em> (gegen <span class="math inline">\(z\in \mathbb R^{}\)</span>) mit <span class="math inline">\(p\geq 1\)</span>, falls eine Konstante <span class="math inline">\(c&gt;0\)</span> existiert sodass
<span class="math display" id="eq:eqn-iterative-cnvrgnc">\[\begin{equation}
|x_{k+1} - z| \leq c|x_k-z|^p,
\tag{3.1}
\end{equation}\]</span>
für <span class="math inline">\(k=1, 2, \dotsc\)</span>.</p>
<p>Ist <span class="math inline">\(p=1\)</span>, so ist <span class="math inline">\(0&lt;c&lt;1\)</span> notwendig für Konvergenz, genannt <em>lineare Konvergenz</em> und das kleinste <span class="math inline">\(c\)</span>, das <a href="iterative-methoden.html#eq:eqn-iterative-cnvrgnc">(3.1)</a> erfüllt, heißt <em>(lineare) Konvergenzrate</em>.</p>
<p>Gilt <span class="math inline">\(p=1\)</span> und gilt <span class="math inline">\(|x_{k+1} - z| \leq c_k|x_k-z|^p\)</span> mit <span class="math inline">\(c_k \to 0\)</span> für <span class="math inline">\(k\to \infty\)</span> heißt die Konvergenz <em>superlinear</em>.</p>
</div>
<div id="rem-conv-iterat" class="JHSAYS">
<p>Wiederum gelten Konvergenzaussagen eigentlich für die Kombination aus Methode und Problem. Dennoch ist es allgemeine Praxis, beispielsweise zu sagen, dass das <em>Newton-Verfahren quadratisch konvergiert</em>.</p>
</div>
<p>Wir stellen fest, dass im Limit (und wenn vor allem <span class="math inline">\(\phi_k \equiv \phi\)</span> ist) gelten muss, dass
<span class="math display">\[\begin{equation*}
x=\phi(x),
\end{equation*}\]</span>
die Lösung (bzw. das was berechnet wurde) ein <em>Fixpunkt</em> der Verfahrensfunktion ist.</p>
<p>In der Tat lassen sich viele iterative Methoden als Fixpunktiteration formulieren und mittels Fixpunktsätzen analysieren. Im ersten Teil dieses Kapitels, werden wir Fixpunktmethoden betrachten.</p>
<p>Als eine Verallgemeinerung, z.B. für den Fall dass <span class="math inline">\(\phi\)</span> tatsächlich von <span class="math inline">\(k\)</span> abhängen soll oder dass kein Fixpunkt sondern beispielsweise ein Minimum angenähert werden soll, werden wir außerdem sogenannte <em>Auxiliary Function Methods</em> einführen und anschauen.</p>
<div id="iterative-methoden-als-fixpunktiteration" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Iterative Methoden als Fixpunktiteration<a href="iterative-methoden.html#iterative-methoden-als-fixpunktiteration" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Um eine iterative Vorschrift, beschrieben durch <span class="math inline">\(\phi\)</span>, als (konvergente) Fixpunktiteration zu charakterisieren, sind zwei wesentliche Bedingungen nachzuweisen</p>
<ol style="list-style-type: decimal">
<li>die gesuchte Lösung <span class="math inline">\(z\)</span> ist ein Fixpunkt des Verfahrens, also <span class="math inline">\(\phi(z)=z\)</span>.</li>
<li>Für einen Startwert <span class="math inline">\(x_0\)</span>, konvergiert die Folge <span class="math inline">\(x_{k+1}:=\phi(x_k)\)</span>, <span class="math inline">\(k=1,2,\dotsc\)</span>, gegen <span class="math inline">\(z\)</span>.</li>
</ol>
<p>Dazu kommen Betrachtungen von Konditionierung, Stabilität und Konvergenzordnung.</p>
<p>Wir beginnen mit etwas analytischer Betrachtung. Sei <span class="math inline">\(g \colon \mathbb R^{}\to \mathbb R^{}\)</span> stetig differenzierbar und sei <span class="math inline">\(z\in \mathbb R^{}\)</span> ein Fixpunkt von <span class="math inline">\(g\)</span>. Dann gilt, dass
<span class="math display">\[\begin{equation*}
\lim_{x\to z} \frac{g(x)-g(z)}{x-z} = \lim_{x\to z} \frac{g(x)-z}{x-z} = g&#39;(z)
\end{equation*}\]</span>
und damit, dass für ein <span class="math inline">\(x_k\)</span> in einer Umgebung <span class="math inline">\(U\)</span> um <span class="math inline">\(z\)</span> gilt, dass
<span class="math display">\[\begin{equation*}
|g(x_k)-z|\leq c |x_k-z|
\end{equation*}\]</span>
mit <span class="math inline">\(c=\sup_{x\in U}|g&#39;(x)|\)</span>.
Daraus können wir direkt ableiten, dass</p>
<ul>
<li>wenn <span class="math inline">\(|g&#39;(z)|&lt;1\)</span> ist, dann ist die Vorschrift <span class="math inline">\(x_{k+1}=\phi(x_k):=g(x_k)\)</span> <em>lokal</em> linear konvergent</li>
<li>wenn <span class="math inline">\(g&#39;(z)=0\)</span> dann sogar <em>superlinear</em></li>
<li>wenn <span class="math inline">\(|g&#39;(z)|&gt;1\)</span> ist, dann divergiert die Folge weg von <span class="math inline">\(z\)</span> (und der Fixpunkt wird <em>abstoßend</em> genannt).</li>
</ul>
<p>Für höhere Konvergenzordnungen wird diese Beobachtung im folgenden Satz verallgemeinert.</p>
<div class="theorem">
<p><span id="thm:thm-smooth-fp-conv" class="theorem"><strong>Theorem 3.1  (Konvergenz höherer Ordnung bei glatter Fixpunktiteration) </strong></span>Sei <span class="math inline">\(g\colon D\subset \mathbb R^{}\to \mathbb R^{}\)</span> <span class="math inline">\(p\)</span>-mal stetig differenzierbar, sei <span class="math inline">\(z\in D\)</span> ein Fixpunkt von <span class="math inline">\(g\)</span>. Dann konvergiert die Fixpunktiteration <span class="math inline">\(x_{k+1}=g(x_k)\)</span> <em>lokal</em> mit Ordnung <span class="math inline">\(p\)</span>, genau dann wenn
<span class="math display">\[\begin{equation*}
g&#39;(z)=\dotsm g^{(p-1)}(z)=0, \quad g^{(p)}\neq 0.
\end{equation*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>Siehe <span class="citation">(Richter and Wick <a href="#ref-RicW17" role="doc-biblioref">2017</a>, Thm. 6.31)</span></p>
</div>
<div id="rem-smooth-fp-conv" class="JHSAYS">
<p>Das <em>genau dann wenn</em> in Satz <a href="iterative-methoden.html#thm:thm-smooth-fp-conv">3.1</a> ist so zu verstehen, dass die Konvergenzordnung genau gleich <span class="math inline">\(p\)</span> ist, was insbesondere beinhaltet, dass wenn <span class="math inline">\(g^{(p)}=0\)</span> ist, die Ordnung eventuell grösser als <span class="math inline">\(p\)</span> ist. (Jan ist verleitet zu denken, dass in diesem Fall die Iteration nicht (oder mit einer niedrigeren Ordnung) konvergieren würde).</p>
</div>
<p>Ist die Iterationsvorschrift linear (wie bei der iterativen Lösung linearer Gleichungssysteme), so ist die erste Ableitung <span class="math inline">\(\phi&#39;\)</span> konstant (und gleich der Vorschrift selbst) und alle weiteren Ableitungen sind <span class="math inline">\(0\)</span>. Dementsprechend, können wir</p>
<ul>
<li>maximal lineare Konvergenz erwarten</li>
<li>(die aber beispielsweise durch dynamische Anpassung von Parametern auf superlinear verbessert werden kann)</li>
<li>dafür aber vergleichsweise direkte Verallgemeinerungen zu mehrdimensionalen und sogar <span class="math inline">\(\infty\)</span>-dimensionalen Problemstellungen.</li>
</ul>
<p>Zur Illustration betrachten wir den <em>Landweber-Algorithmus</em> zur näherungsweisen Lösung von “<span class="math inline">\(Ax=b\)</span>”.
Dieser Algorithmus wird zwar insbesondere nicht verwendet um ein lineares Gleichungssystem zu lösen, durch die Formulierung für möglicherweise überbestimmte Systeme und die Verbindung zur iterativen Optimierung hat er aber praktische Anwendungen in <em>compressed sensing</em> und auch beim <em>supervised learning</em> gefunden; vgl. <a href="https://en.wikipedia.org/wiki/Landweber_iteration">wikipedia:Landweber_iteration</a>.</p>
<div class="definition">
<p><span id="def:def-landweber-alg" class="definition"><strong>Definition 3.2  (Landweber Iteration) </strong></span>Sei <span class="math inline">\(A\in \mathbb R^{m\times n}\)</span> und <span class="math inline">\(b\in \mathbb R^{m}\)</span>. Dann ist, ausgehend von einem Startwert <span class="math inline">\(x_0 \in \mathbb R^{n}\)</span>, die <em>Landweber Iteration</em> definiert über
<span class="math display">\[\begin{equation*}
x_{k+1} = x_k - \gamma A^T(Ax_k -b ),
\end{equation*}\]</span>
wobei der Parameter <span class="math inline">\(\gamma\)</span> als <span class="math inline">\(0&lt;\gamma&lt; \frac{2}{\|A\|_2}\)</span> gewählt wird.</p>
</div>
<p>Zur Illustration der Argumente, die die Konvergenz einer Fixpunktiteration mit linearer Verfahrensfunktion herleiten, zeigen wir die Konvergenz im Spezialfall, dass <span class="math inline">\(Ax=b\)</span> ein reguläres lineares Gleichungssystem ist.</p>
<div class="theorem">
<p><span id="thm:thm-lw-conv" class="theorem"><strong>Theorem 3.2  (Konvergenz der Landweber Iteration) </strong></span>Unter den Voraussetzungen von Definition <a href="iterative-methoden.html#def:def-landweber-alg">3.2</a> und für <span class="math inline">\(m=n\)</span> und <span class="math inline">\(A\in \mathbb R^{n\times n}\)</span> regulär, konvergiert die Landweber Iteration linear für einen beliebigen Startwert <span class="math inline">\(x_0\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>Ist das Gleichungssystem <span class="math inline">\(Az=b\)</span> eindeutig lösbar, bekommen wir direkt, dass
<span class="math display">\[\begin{equation*}
\begin{split}
x_{k+1} - z &amp;= x_k - \gamma A^T(Ax_k -b ) - z  \\
&amp;= x_k - \gamma A^TAx_k -\gamma A^Tb - z \\
&amp;= (I-\gamma A^TA)x_k -\gamma A^TAz - z \\
&amp;= (I-\gamma A^TA)(x_k - z)
\end{split}
\end{equation*}\]</span>
Damit ergibt eine Abschätzung in der <span class="math inline">\(2\)</span>-Norm und der induzierten Matrixnorm, dass
<span class="math display">\[\begin{equation*}
\|x_{k+1}-z\|_2 \leq \|I-\gamma A^TA\|_2\|x_k-z\|_2
\end{equation*}\]</span>
gilt, was lineare Konvergenz mit der Rate <span class="math inline">\(c=\|I-\gamma A^TA\|_2\)</span> bedeutet, wobei <span class="math inline">\(c&lt;1\)</span> gilt nach der getroffenen Voraussetzung, dass <span class="math inline">\(0&lt;\gamma&lt;\frac{2}{\|A^TA\|_2}\)</span> ist.</p>
</div>
<div id="rem-fpconv-iteration-contraction" class="JHSAYS">
<p>Das Prinzip dieser Beweise ist festzustellen, dass die Verfahrensfunktion in der Nähe des Fixpunkts eine <em>Kontraktion</em> ist, d.h. Lipschitz-stetig mit Konstante <span class="math inline">\(L&lt;1\)</span>.</p>
</div>
</div>
<div id="gradientenabstiegsverfahren" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Gradientenabstiegsverfahren<a href="iterative-methoden.html#gradientenabstiegsverfahren" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Anstelle der Nullstellensuche behandeln wir jetzt die Aufgabe
<span class="math display">\[\begin{equation*}
f(x) \to \min_{x\in \mathbb R^{n}}
\end{equation*}\]</span>
für eine Funktion <span class="math inline">\(f \colon \mathbb R^{n} \to \mathbb R^{}\)</span>, also die Aufgabe ein <span class="math inline">\(z^*\in \mathbb R^{n}\)</span> zu finden, für welches der Wert von <span class="math inline">\(f\)</span> minimal wird.</p>
<p>Ist <span class="math inline">\(f\)</span> differenzierbar (der Einfachheit halber nehmen wir an, dass <em>totale</em> Differenzierbarkeit vorliegt; es würde aber Differenzierbarkeit in einer beliebigen Richtung, also <em>Gateaux</em>-Differenzierbarkeit, genügen), so gilt, dass in einem Punkt <span class="math inline">\(x_0\)</span>, der Gradient <span class="math inline">\(\nabla f(x_0)\)</span> (ein Vektor im <span class="math inline">\(\mathbb R^{n}\)</span>) in die Richtung des stärksten Wachstums zeigt und der negative Gradient <span class="math inline">\(-\nabla f(x_0)\)</span> in die Richtung, in der <span class="math inline">\(f\)</span> kleiner wird.</p>
<p>Auf der Suche nach einem Minimum könnten wir also ausnutzen, dass
<span class="math display">\[\begin{equation*}
f(x_0 - \gamma_0 \nabla f(x_0)):=f(x_1)   &lt; f(x_0)
\end{equation*}\]</span>
falls <span class="math inline">\(\gamma_0\)</span> nur genügend klein ist und <span class="math inline">\(\nabla f(x_0) \neq 0\)</span>.</p>
<div id="rem-gamma-zerograd" class="JHSAYS">
<p>Was ist, wenn <span class="math inline">\(\nabla f(x_0) = 0\)</span> ist und warum gibt es andernfalls so ein <span class="math inline">\(\gamma_0\)</span> und wie könnten wir es systematisch bestimmen?</p>
</div>
<p>Diese Beobachtung am nächsten Punkt <span class="math inline">\(x_1\)</span> wiederholt, führt auf des <em>Gradientenabstiegsverfahren</em>.</p>
<div class="definition">
<p><span id="def:def-grad-descent" class="definition"><strong>Definition 3.3  (Gradientenabstiegsverfahren) </strong></span>Sei <span class="math inline">\(f\colon \mathbb R^{n} \to \mathbb R^{}\)</span> differenzierbar, dann heißt die Iteration
<span class="math display" id="eq:eqn-grad-desc">\[\begin{equation}
x_{k+1} := x_k - \gamma_k\nabla f(x_k)
\tag{3.2}
\end{equation}\]</span>
für passend gewählte <span class="math inline">\(\gamma_k&gt;0\)</span>, das
Gradientenabstiegsverfahren zur Berechnung eines Minimums von <span class="math inline">\(f\)</span>.</p>
</div>
<div class="lemma">
<p><span id="lem:lem-graddesc-as-fp" class="lemma"><strong>Lemma 3.1  (Gradientenabstieg als konvergente Fixpunkt Iteration) </strong></span>Sei <span class="math inline">\(f\colon D\subset \mathbb R^{n}\to \mathbb R\)</span> konvex und zweimal stetig differenzierbar auf <span class="math inline">\(D\)</span> offen. Ist <span class="math inline">\(z^*\in D\)</span> ein Minimum von <span class="math inline">\(f\)</span> und sei <span class="math inline">\(\overline \lambda\)</span> die <em>Lipschitz-Konstante</em> von <span class="math inline">\(\nabla f\)</span>, dann definiert <a href="iterative-methoden.html#eq:eqn-grad-desc">(3.2)</a> mit <span class="math inline">\(\gamma_k \equiv \frac 2{\overline \lambda}\)</span> eine konvergente Fixpunktiteration für <span class="math inline">\(\phi(x) = x-\gamma \nabla f(x)\)</span> mit einem lokalen Minimum <span class="math inline">\(z^*\)</span> von <span class="math inline">\(f\)</span> als Fixpunkt.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span>Vorlesung.</p>
</div>
<p>Die vorhergegangenen Überlegungen gingen von <span class="math inline">\(z^*\)</span> innerhalb eines offenen Definitionsbereichs <span class="math inline">\(D\)</span> von <span class="math inline">\(f\)</span> aus, wo ein Minimum durch <span class="math inline">\(\nabla f(x^*)=0\)</span> und <span class="math inline">\(f(x^*)\leq f(x)\)</span> für alle <span class="math inline">\(x\)</span> aus einer Umgebung von <span class="math inline">\(x^*\)</span> gegeben ist.</p>
<p>Ein typischer Anwendungsfall ist jedoch, dass <span class="math inline">\(x^*\)</span> in einem zulässigen Bereich <span class="math inline">\(C\)</span> liegen muss, der eine echte Teilmenge von <span class="math inline">\(D\)</span> ist.
Dann besteht die Möglichkeit, dass ein (lokales) Minimum am Rand des Bereichs <span class="math inline">\(C\)</span> vorliegt (wo die Funktion <span class="math inline">\(f\)</span> zwar weiter fällt, aber “das Ende” der Zulässigkeit erreicht ist).</p>
<p>Ist <span class="math inline">\(C\subset \mathbb R^{n}\)</span> konvex und abgeschlossen, so gilt folgendes allgemeine Resultat (dessen Argumente und Voraussetzungen auch leicht auf beispielsweise Funktionen auf allgemeinen Hilberträumen oder Mengen die nur lokal konvex sind angepasst werden können).</p>
<div class="theorem">
<p><span id="thm:thm-prj-grad-desc" class="theorem"><strong>Theorem 3.3  (Projiziertes Gradientenabstiegsverfahren) </strong></span>Sei <span class="math inline">\(C \subset \mathbb R^{n}\)</span> konvex und abgeschlossen, dann ist die Projektion <span class="math inline">\(P_C\colon \mathbb R^{n} \to C\)</span> mittels
<span class="math display">\[\begin{equation*}
P_C(x) := x^*,
\end{equation*}\]</span>
wobei <span class="math inline">\(x^*\)</span> das Minimierungsproblem
<span class="math display">\[\begin{equation*}
\min_{z\in C} \|x-z\|_2
\end{equation*}\]</span>
löst, wohldefiniert.</p>
<p>Sei ferner <span class="math inline">\(f\colon D \to \mathbb R^{}\)</span>, mit <span class="math inline">\(C \subset D\)</span>, konvex und differenzierbar mit Lipschitz-stetigem Gradienten mit Konstante <span class="math inline">\(L\)</span>. Dann konvergiert das projizierte Gradientenabstiegsverfahren
<span class="math display" id="eq:eqn-prj-grad-desc">\[\begin{equation}
x_{k+1} := P_C(x_k - \gamma_k\nabla f(x_k))
\tag{3.3}
\end{equation}\]</span>
für jeden Anfangswert <span class="math inline">\(x_0\in D\)</span> und beliebige Wahl von <span class="math inline">\(\gamma_k &lt; \frac 1L\)</span> zu einem lokalen Minimum <span class="math inline">\(z^*\in C\)</span> von <span class="math inline">\(f\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span>Technisch…</p>
</div>
</div>
<div id="auxiliary-function-methods" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Auxiliary Function Methods<a href="iterative-methoden.html#auxiliary-function-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In manchen Fällen ist es hilfreich, wenn das Problem selbst iterativ definiert wird.
Dann wird in jedem Schritt ein vereinfachtes Problem gelöst und mit der gewonnenen Information, kann das Problem dem eigentlichen aber schwierigen Originalproblem näher gebracht werden.</p>
<p>Als Beispiel betrachten wir das Problem
<span class="math display" id="eq:eqn-exa-cnstrnt-optiprob">\[\begin{equation}
f(x)=x_1^2+x_2^2 \to \min_{x\in D\subset \mathbb R^{2}}, \quad \text{wobei }D:=\{x\in \mathbb R^{2}\,|\, x_1+x_2 \geq 0\}.
\tag{3.4}
\end{equation}\]</span></p>
<p>Zwar ist hier das projizierte Gradientenabstiegsverfahren unmittelbar anwendbar, wir werden aber sehen, dass wir mit einer Hilfsfunktion, sogar die analytische Lösung direkt ablesen können.</p>
<p>Für <span class="math inline">\(k=1,2,\dotsc\)</span>, sei das Hilfsproblem definiert als
<span class="math display" id="eq:eqn-exa-relaxed-optiprob">\[\begin{equation}
B_k(x):=x_1^2+x_2^2 - \frac{1}{k}\log(x_1+x_2-1)\to \inf_C,
\tag{3.5}
\end{equation}\]</span>
wobei <span class="math inline">\(C=\{x\,|\,x_1+x_2&gt;0\}\)</span>. Aus dem “0-setzen” der partiellen Ableitungen von <span class="math inline">\(B_k\)</span>, bekommen wir
<span class="math display">\[\begin{equation*}
x_{k,1}=x_{k,2} = \frac 14 + \frac 14 \sqrt{1 + \frac 4k},
\end{equation*}\]</span>
also eine Folge, die zum Minimum des eigentlichen Problems konvergiert.</p>
<p>Zur Analyse solcher Verfahren, allgemein geschrieben als
<span class="math display" id="eq:eqn-gen-af-method">\[\begin{equation}
G_k(x) = f(x) + g_k(x) \to \min_C, \quad k=1,2,\dotsc
\tag{3.6}
\end{equation}\]</span>
werden die folgenden zwei Bedingungen gerne herangenommen:</p>
<ol style="list-style-type: decimal">
<li><p>Die Iteration <a href="iterative-methoden.html#eq:eqn-gen-af-method">(3.6)</a> heißt <em>auxiliary function</em> (AF) Methode, falls <span class="math inline">\(g_k(x)\geq 0\)</span>, für alle <span class="math inline">\(k\in \mathbb N\)</span> und <span class="math inline">\(x\in C\)</span>, <span class="math inline">\(g_k(x_{k-1})=0\)</span>.</p></li>
<li><p>Die Iteration gehört zur <em>SUMMA</em> Klasse, falls <span class="math inline">\(G_k(x)-G_k(x_k) \geq g_{k+1}(x)\)</span>.</p></li>
</ol>
<p>Unter der 1. Annahme gilt sofort, dass
<span class="math display">\[\begin{equation*}
f(x_{k}) \leq f(x_{k}) + g_k(x_k) = G_k(x_k) \leq G_k(x_{k-1}) = f(x_{k-1}) + g_k(x_{k-1}) = f(x_{k-1}),
\end{equation*}\]</span>
also dass die Folge <span class="math inline">\(\{f(x_k)\}_{k\in \mathbb N}\)</span> monoton fallend ist.</p>
<p>Aus der 2. Annahme folgt dann, dass <span class="math inline">\(f(x_k) \to \beta^*=\inf_{x\in c}f(x)\)</span>, für <span class="math inline">\(k\to \infty\)</span>, was sich wie folgt argumentieren läßt:</p>
<p>Angenommen, <span class="math inline">\(f(x_k) \to \beta &gt; \beta^*\)</span>, dann existiert ein <span class="math inline">\(z\in C\)</span>, sodass <span class="math inline">\(\beta &gt; f(z) \geq \beta^*\)</span>. Dann ist, der 2. 2. Annahme nach,
<span class="math display">\[\begin{equation*}
\begin{split}
g_k(z) - g_{k+1}(z) &amp;= g_k(z) - (G_k(z)-G_k(x_k))    \\
&amp;=g_k(z) - (f(z) + g_k(z) - f(x_k) - g_k(x_k)) \\
&amp;\quad \geq f(z) - \beta + g_k(x_k) \geq f(z) - \beta &gt; 0,
\end{split}
\end{equation*}\]</span>
was impliziert, dass <span class="math inline">\(0\leq g_{k+1}(z)&lt;g_k(z)+c\)</span>, für alle <span class="math inline">\(k\)</span> und eine konstantes <span class="math inline">\(c&gt;0\)</span>, was ein Widerspruch ist.</p>
<p>Wir rechnen nach, dass <a href="iterative-methoden.html#eq:eqn-exa-relaxed-optiprob">(3.5)</a> die Annahmen 1. und 2. erfüllt (allerdings erst nach einigen äquivalenten Umformungen).</p>
<p>Zunächst halten wir fest, dass die Iteration in <a href="iterative-methoden.html#eq:eqn-exa-relaxed-optiprob">(3.5)</a> geschrieben werden kann als
<span class="math display" id="eq:eqn-min-barrier">\[\begin{equation}
B_k(x) = f(x) + \frac 1k b(x) \to \min
\tag{3.7}
\end{equation}\]</span>
was, da eine Skalierung das Minimum nicht änder ebensowenig wie die Addition eines konstanten Termes (konstant bezüglich <span class="math inline">\(x\)</span>),
äquivalent ist zu
<span class="math display">\[\begin{equation*}
G_k(x) = f(x) + g_k(x)
\end{equation*}\]</span>
mit
<span class="math display">\[\begin{equation*}
g_k(x) = [(k-1)f(x) + b(x)] - [(k-1)f(x_{k-1}) + b(x_{k-1})].
\end{equation*}\]</span></p>
<p>Wir rechnen direkt nach, dass <span class="math inline">\(g_k(x)\geq 0\)</span> ist (folgt daraus, dass <span class="math inline">\(x_{k-1}\)</span> optimal für <span class="math inline">\(G_{k-1}\)</span> ist), dass <span class="math inline">\(g_k(x_{k-1})=0\)</span> ist, und dass <span class="math inline">\(G_k(x)-G_k(x_k)=g_{k+1}(x)\)</span> ist (dafür muss ein bisschen umgeformt werden), sodass die Voraussetzungen für AF und SUMMA erfüllt sind.</p>
<p>Zum Abschluss einige Bemerkungen</p>
<ul>
<li>das allgemeine <span class="math inline">\(b\)</span> in <a href="iterative-methoden.html#eq:eqn-min-barrier">(3.7)</a> und im speziellen in <a href="iterative-methoden.html#eq:eqn-exa-relaxed-optiprob">(3.5)</a> ist eine sogenannte <em>barrier</em> Funktion, die beispielsweise einen zulässigen Bereich als <span class="math inline">\(C=\{x\,|\, b(x)&lt; \infty\}\)</span> definiert.</li>
<li>weitere Methoden der Optimierung, die in die betrachteten (AF) Klassen fallen sind beispielsweise <em>Majorization Minimization</em>, <em>Expectation Maximization</em>, <em>Proximal Minimization</em> oder <em>Regularized Gradient Descent</em>.</li>
<li>Eine schöne Einführung und Übersicht liefert das Skript <em>Lecture Notes on Iterative Optimization Algorithms</em> <span class="citation">(Byrne <a href="#ref-Byr14" role="doc-biblioref">2014</a>)</span>.</li>
</ul>
</div>
<div id="übungen-2" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Übungen<a href="iterative-methoden.html#übungen-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Bestimmen Sie die Konvergenzordnung und die Rate für das Intervallschachtelungsverfahren zur Nullstellenberechnung.</p></li>
<li><p>Benutzen Sie Satz <a href="iterative-methoden.html#thm:thm-smooth-fp-conv">3.1</a> um zu zeigen, dass aus <span class="math inline">\(f\)</span> zweimal stetig differenzierbar und <span class="math inline">\(f(z)=0\)</span>, <span class="math inline">\(f&#39;(z)\neq 0\)</span> für ein <span class="math inline">\(z\in D(f)\)</span> folgt, dass das Newton-Verfahren zur Berechnung von <span class="math inline">\(z\)</span> lokal quadratisch konvergiert. <em>Hinweis</em>: Hier ist es wichtig zunächst zu verstehen, was die Funktion <span class="math inline">\(f\)</span> ist und was die Verfahrensfunktion <span class="math inline">\(\phi\)</span> ist.</p></li>
<li><p>Bestimmen sie die Funktion <span class="math inline">\(h\)</span> in <span class="math inline">\(\phi(x) = x+h(x)f(x)\)</span> derart, dass unter den Bedingungen von 2. die Vorschrift <span class="math inline">\(\phi\)</span> einen Fixpunkt in <span class="math inline">\(z\)</span> hat und derart, dass die Iteration quadratisch konvergiert.</p></li>
<li><p>Erklären Sie an Hand von Satz <a href="iterative-methoden.html#thm:thm-smooth-fp-conv">3.1</a> (und den vorhergegangenen Überlegungen) warum Newton für das Problem <em>finde <span class="math inline">\(x\)</span>, so dass <span class="math inline">\(x^2=0\)</span> ist</em> <strong>nicht</strong> quadratisch (aber doch superlinear) konvergiert.</p></li>
<li><p>Beweisen Sie, dass für <span class="math inline">\(0&lt;\gamma&lt; \frac{2}{\|A^TA\|_2}\)</span> gilt, dass<span class="math inline">\(\|I-\gamma A^TA\|_2&lt;1\)</span> für beliebige <span class="math inline">\(A\in \mathbb R^{m \times n}\)</span>.</p></li>
<li><p>Rechnen Sie nach, dass die Landweber Iteration aus Definition <a href="iterative-methoden.html#def:def-landweber-alg">3.2</a> einem gedämpften Gradientenabstiegsverfahren für <span class="math inline">\(\|Ax-b\|_2^2 \to \min_{x\in \mathbb R^{m}}\)</span> entspricht.</p></li>
<li><p>Implementieren Sie das projizierte Gradientenabstiegsverfahren für <a href="iterative-methoden.html#eq:eqn-exa-cnstrnt-optiprob">(3.4)</a> und das <em>nichtprojizierte</em> aber an <span class="math inline">\(k\)</span> angepasste Gradientenabstiegsverfahren für <a href="iterative-methoden.html#eq:eqn-exa-relaxed-optiprob">(3.5)</a>. Vergleichen Sie die Konvergenz für verschiedene Startwerte.</p></li>
</ol>

</div>
</div>
<h3>Referenzen<a href="referenzen.html#referenzen" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references">
<div id="ref-Byr14">
<p> Byrne, C.L.: Lecture notes on iterative optimization algorithms, <a href="https://faculty.uml.edu/cbyrne/IOIPNotesOct2014.pdf">https://faculty.uml.edu/cbyrne/IOIPNotesOct2014.pdf</a>, (2014)</p>
</div>
<div id="ref-RicW17">
<p> Richter, T., Wick, T.: Einführung in die numerische Mathematik. Begriffe, Konzepte und zahlreiche Anwendungsbeispiele. Heidelberg: Springer Spektrum (2017)</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fehler-und-konditionierung.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stochastisches-gradientenverfahren.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["NdML.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
