<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Stochastisches Gradientenverfahren | Numerik des Maschinellen Lernens</title>
  <meta name="description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Stochastisches Gradientenverfahren | Numerik des Maschinellen Lernens" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  <meta name="github-repo" content="highlando/script-ndml" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Stochastisches Gradientenverfahren | Numerik des Maschinellen Lernens" />
  
  <meta name="twitter:description" content="Vorlesungsnotizen zu meiner integrierten Vorlesung im SoSe 2024" />
  

<meta name="author" content="Jan Heiland" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="iterative-methoden.html"/>
<link rel="next" href="ein-nn-beispiel.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">NdML</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="chapter" data-level="1" data-path="einführung.html"><a href="einführung.html"><i class="fa fa-check"></i><b>1</b> Einführung</a>
<ul>
<li class="chapter" data-level="1.1" data-path="einführung.html"><a href="einführung.html#was-ist-ein-algorithmus"><i class="fa fa-check"></i><b>1.1</b> Was ist ein Algorithmus</a></li>
<li class="chapter" data-level="1.2" data-path="einführung.html"><a href="einführung.html#konsistenz-stabilität-genauigkeit"><i class="fa fa-check"></i><b>1.2</b> Konsistenz, Stabilität, Genauigkeit</a></li>
<li class="chapter" data-level="1.3" data-path="einführung.html"><a href="einführung.html#rechenkomplexität"><i class="fa fa-check"></i><b>1.3</b> Rechenkomplexität</a></li>
<li class="chapter" data-level="1.4" data-path="einführung.html"><a href="einführung.html#literatur"><i class="fa fa-check"></i><b>1.4</b> Literatur</a></li>
<li class="chapter" data-level="1.5" data-path="einführung.html"><a href="einführung.html#übungen"><i class="fa fa-check"></i><b>1.5</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html"><i class="fa fa-check"></i><b>2</b> Fehler und Konditionierung</a>
<ul>
<li class="chapter" data-level="2.1" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#fehler"><i class="fa fa-check"></i><b>2.1</b> Fehler</a></li>
<li class="chapter" data-level="2.2" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#kondition"><i class="fa fa-check"></i><b>2.2</b> Kondition</a></li>
<li class="chapter" data-level="2.3" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#kondition-der-grundrechenarten"><i class="fa fa-check"></i><b>2.3</b> Kondition der Grundrechenarten</a></li>
<li class="chapter" data-level="2.4" data-path="fehler-und-konditionierung.html"><a href="fehler-und-konditionierung.html#übungen-1"><i class="fa fa-check"></i><b>2.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="iterative-methoden.html"><a href="iterative-methoden.html"><i class="fa fa-check"></i><b>3</b> Iterative Methoden</a>
<ul>
<li class="chapter" data-level="3.1" data-path="iterative-methoden.html"><a href="iterative-methoden.html#iterative-methoden-als-fixpunktiteration"><i class="fa fa-check"></i><b>3.1</b> Iterative Methoden als Fixpunktiteration</a></li>
<li class="chapter" data-level="3.2" data-path="iterative-methoden.html"><a href="iterative-methoden.html#gradientenabstiegsverfahren"><i class="fa fa-check"></i><b>3.2</b> Gradientenabstiegsverfahren</a></li>
<li class="chapter" data-level="3.3" data-path="iterative-methoden.html"><a href="iterative-methoden.html#auxiliary-function-methods"><i class="fa fa-check"></i><b>3.3</b> Auxiliary Function Methods</a></li>
<li class="chapter" data-level="3.4" data-path="iterative-methoden.html"><a href="iterative-methoden.html#übungen-2"><i class="fa fa-check"></i><b>3.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html"><i class="fa fa-check"></i><b>4</b> Stochastisches Gradientenverfahren</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#motivation-und-algorithmus"><i class="fa fa-check"></i><b>4.1</b> Motivation und Algorithmus</a></li>
<li class="chapter" data-level="4.2" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#iterative_method"><i class="fa fa-check"></i><b>4.2</b> Stochastisches Abstiegsverfahren</a></li>
<li class="chapter" data-level="4.3" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#konvergenzanalyse"><i class="fa fa-check"></i><b>4.3</b> Konvergenzanalyse</a></li>
<li class="chapter" data-level="4.4" data-path="stochastisches-gradientenverfahren.html"><a href="stochastisches-gradientenverfahren.html#übungen-3"><i class="fa fa-check"></i><b>4.4</b> Übungen</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html"><i class="fa fa-check"></i><b>5</b> Ein NN Beispiel</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#der-penguins-datensatz"><i class="fa fa-check"></i><b>5.1</b> Der PENGUINS Datensatz</a></li>
<li class="chapter" data-level="5.2" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#ein-2-layer-neuronales-netz-zur-klassifizierung"><i class="fa fa-check"></i><b>5.2</b> Ein <em>2</em>-Layer Neuronales Netz zur Klassifizierung</a></li>
<li class="chapter" data-level="5.3" data-path="ein-nn-beispiel.html"><a href="ein-nn-beispiel.html#beispiel-implementierung"><i class="fa fa-check"></i><b>5.3</b> Beispiel Implementierung</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html"><i class="fa fa-check"></i><b>6</b> Singulärwert Zerlegung</a>
<ul>
<li class="chapter" data-level="6.1" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#definition-und-eigenschaften"><i class="fa fa-check"></i><b>6.1</b> Definition und Eigenschaften</a></li>
<li class="chapter" data-level="6.2" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#numerische-berechnung"><i class="fa fa-check"></i><b>6.2</b> Numerische Berechnung</a></li>
<li class="chapter" data-level="6.3" data-path="singulärwert-zerlegung.html"><a href="singulärwert-zerlegung.html#aufgaben"><i class="fa fa-check"></i><b>6.3</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html"><i class="fa fa-check"></i><b>7</b> PCA und weitere SVD Anwendungen</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#proper-orthogonal-decomposition-pod"><i class="fa fa-check"></i><b>7.1</b> Proper-Orthogonal Decomposition – POD</a></li>
<li class="chapter" data-level="7.2" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#simultane-diagonalisierung"><i class="fa fa-check"></i><b>7.2</b> Simultane Diagonalisierung</a></li>
<li class="chapter" data-level="7.3" data-path="pca-und-weitere-svd-anwendungen.html"><a href="pca-und-weitere-svd-anwendungen.html#pca"><i class="fa fa-check"></i><b>7.3</b> PCA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>8</b> Support Vector Machines</a>
<ul>
<li class="chapter" data-level="8.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#problemstellung"><i class="fa fa-check"></i><b>8.1</b> Problemstellung</a></li>
<li class="chapter" data-level="8.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#maximierung-des-minimalen-abstands"><i class="fa fa-check"></i><b>8.2</b> Maximierung des Minimalen Abstands</a></li>
<li class="chapter" data-level="8.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#aufgaben-1"><i class="fa fa-check"></i><b>8.3</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html"><i class="fa fa-check"></i><b>9</b> Best and Universal Approximation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html#universal-approximation"><i class="fa fa-check"></i><b>9.1</b> Universal Approximation</a></li>
<li class="chapter" data-level="9.2" data-path="best-and-universal-approximation.html"><a href="best-and-universal-approximation.html#aufgaben-2"><i class="fa fa-check"></i><b>9.2</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html"><i class="fa fa-check"></i><b>10</b> Automatisches (Algorithmisches) Differenzieren</a>
<ul>
<li class="chapter" data-level="10.1" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#andere-differentiationsmethoden"><i class="fa fa-check"></i><b>10.1</b> Andere Differentiationsmethoden</a></li>
<li class="chapter" data-level="10.2" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#anwendungen"><i class="fa fa-check"></i><b>10.2</b> Anwendungen</a></li>
<li class="chapter" data-level="10.3" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#vorwärts--und-rückwärtsakkumulation"><i class="fa fa-check"></i><b>10.3</b> Vorwärts- und Rückwärtsakkumulation</a></li>
<li class="chapter" data-level="10.4" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#ad-vorwärtsmodus"><i class="fa fa-check"></i><b>10.4</b> AD – Vorwärtsmodus</a></li>
<li class="chapter" data-level="10.5" data-path="automatisches-algorithmisches-differenzieren.html"><a href="automatisches-algorithmisches-differenzieren.html#rückwärtsmodus"><i class="fa fa-check"></i><b>10.5</b> Rückwärtsmodus</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html"><i class="fa fa-check"></i><b>11</b> Implementierungen, Anwendungsbeispiele, Backpropagation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#exkurs-gradienten-und-repräsentation"><i class="fa fa-check"></i><b>11.1</b> Exkurs – Gradienten und Repräsentation</a></li>
<li class="chapter" data-level="11.2" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#backpropagation"><i class="fa fa-check"></i><b>11.2</b> Backpropagation</a></li>
<li class="chapter" data-level="11.3" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#praktische-berechnung-des-gradienten"><i class="fa fa-check"></i><b>11.3</b> Praktische Berechnung des Gradienten</a></li>
<li class="chapter" data-level="11.4" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#implementierungen-und-beispiele"><i class="fa fa-check"></i><b>11.4</b> Implementierungen und Beispiele</a></li>
<li class="chapter" data-level="11.5" data-path="implementierungen-anwendungsbeispiele-backpropagation.html"><a href="implementierungen-anwendungsbeispiele-backpropagation.html#aufgaben-3"><i class="fa fa-check"></i><b>11.5</b> Aufgaben</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="nachklapp.html"><a href="nachklapp.html"><i class="fa fa-check"></i><b>12</b> Nachklapp</a></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Numerik des Maschinellen Lernens</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastisches-gradientenverfahren" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Stochastisches Gradientenverfahren<a href="stochastisches-gradientenverfahren.html#stochastisches-gradientenverfahren" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Das stochastische Gradientenverfahren formuliert den Fall, dass im <span class="math inline">\(k\)</span>-ten Schritt anstelle des eigentlichen Gradienten <span class="math inline">\(\nabla f(x_k)\in \mathbb R^{n}\)</span> eine Schätzung <span class="math inline">\(g(x_k, \xi)\in \mathbb R^{n}\)</span> vorliegt, die eine zufällige Komponente in Form einer Zufallsvariable <span class="math inline">\(\xi\)</span> hat. Dabei wird angenommen, dass <span class="math inline">\(g(x_k, \xi)\)</span> <em>erwartungstreu</em> ist, das heißt
<span class="math display">\[\begin{equation*}
\mathbb E_\xi [g(x_k, \xi)] = \nabla f(x_k),
\end{equation*}\]</span>
wobei <span class="math inline">\(\mathbb E_\xi\)</span> den Erwartungswert bezüglich der Variablen <span class="math inline">\(\xi\)</span> beschreibt.</p>
<div id="motivation-und-algorithmus" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Motivation und Algorithmus<a href="stochastisches-gradientenverfahren.html#motivation-und-algorithmus" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Im <em>Maschinellen Lernen</em> oder allgemeiner in der <em>nichtlinearen Regression</em> spielt die Minimierung von Zielfunktionalen in Summenform
<span class="math display">\[\begin{equation*}
Q(w) = \frac{1}{N}\sum_{i=1}^N Q_i(w)
\end{equation*}\]</span>
eine Rolle, wobei der Parametervektor <span class="math inline">\(w\in \mathbb R^n\)</span>, der
<span class="math inline">\(Q\)</span> minimiert, gefunden oder geschätzt werden soll.
Jede der Summandenfunktionen <span class="math inline">\(Q_i\)</span> ist typischerweise assoziiert mit einem <span class="math inline">\(i\)</span>-ten Datenpunkt (einer Beobachtung) beispielsweise aus einer Menge von Trainingsdaten.</p>
<p>Sei beispielsweise eine parametrisierte nichtlineare Funktion <span class="math inline">\(T_w\colon \mathbb R^{m}\to \mathbb R^{n}\)</span> gegeben die durch Optimierung eines Parametervektors <span class="math inline">\(w\)</span> an Datenpunkte <span class="math inline">\((x_i, y_i)\subset \mathbb R^{n}\times \mathbb R^{m}\)</span>, <span class="math inline">\(i=1, \dotsc, N\)</span>, <em>gefittet</em> werden soll, ist die <em>mittlere quadratische Abweichung</em>
<span class="math display">\[\begin{equation*}
\mathsf{MSE}\,(w) := \frac 1N \sum_{i=1}^N \|N(x_i)-y_i\|_2^2
\end{equation*}\]</span>
genannt <em>mean squared error</em>, ein naheliegendes und oft gewähltes Optimierungskriterium.</p>
<p>Um obige Kriterien zu minimieren, würde ein sogenannter Gradientenabstiegsverfahren den folgenden Minimierungsschritt</p>
<p><span class="math display">\[\begin{equation*}
w^{k+1} := w^{k} - \eta \nabla Q(w^k) = w^k - \eta \frac{1}{N} \sum_{i=1}^N \nabla Q_i(w^k),
\end{equation*}\]</span>
iterativ anwenden, wobei <span class="math inline">\(\eta\)</span> die Schrittweite ist, die besonders in der <em>ML</em> community oft auch <em>learning rate</em> genannt wird.</p>
<p>Die Berechnung der Abstiegsrichtung erfordert hier also in jedem Schritt die Bestimmung von <span class="math inline">\(N\)</span> Gradienten <span class="math inline">\(\nabla Q_i(w^k)\)</span> der Summandenfunktionen. Wenn <span class="math inline">\(N\)</span> groß ist, also beispielsweise viele Datenpunkte in einer Regression beachtet werden sollen, dann ist die Berechnung entsprechend aufwändig.</p>
<p>Andererseits entspricht die Abstiegsrichtung
<span class="math display">\[\begin{equation*}
\frac{1}{N} \sum_{i=1}^N \nabla Q_i(w^k)
\end{equation*}\]</span>
dem Mittelwert der Gradienten aller <span class="math inline">\(Q_i\)</span>s am Punkt <span class="math inline">\(w_k\)</span>, der durch ein kleineres Sample</p>
<p><span class="math display">\[\begin{equation*}
\frac{1}{N} \sum_{i=1}^N \nabla Q_i(w^k) \approx \frac{1}{|\mathcal J|} \sum_{j\in \mathcal J} \nabla Q_j(w^k),
\end{equation*}\]</span></p>
<p>angenähert werden könnte, wobei <span class="math inline">\(\mathcal J \subset \{1, \dotsc, N\}\)</span> eine Indexmenge ist, die den <em>batch</em> der zur Approximation gewählten <span class="math inline">\(Q_i\)</span>s beschreibt.</p>
</div>
<div id="iterative_method" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Stochastisches Abstiegsverfahren<a href="stochastisches-gradientenverfahren.html#iterative_method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Beim stochastischen (oder “Online”) Gradientenabstieg wird der wahre Gradient von <span class="math inline">\(Q(w^k)\)</span> durch einen Gradienten bei einer einzelnen Probe angenähert:
<span class="math display">\[\begin{equation*}
w^{k+1} = w^k-\eta \nabla Q_j(w^k),
\end{equation*}\]</span>
mit <span class="math inline">\(j\in \{1,\dotsc, N\}\)</span> zufällig gewählt (ohne zurücklegen).</p>
<p>Während der Algorithmus den Trainingssatz durchläuft, führt er die obige Aktualisierung für jede Trainingsprobe durch. Es können mehrere Durchgänge (sogenannte <em>epochs</em>) über den Trainingssatz gemacht werden, bis der Algorithmus konvergiert. Wenn dies getan wird, können die Daten für jeden Durchlauf gemischt werden, um Zyklen zu vermeiden. Typische Implementierungen verwenden zudem eine adaptive Lernrate, damit der Algorithmus überhaupt oder schneller konvergiert.</p>
<p>Die wesentlichen Schritte als Algorithmus sehen wie folgt aus:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="stochastisches-gradientenverfahren.html#cb6-1" tabindex="-1"></a><span class="co">###################################################</span></span>
<span id="cb6-2"><a href="stochastisches-gradientenverfahren.html#cb6-2" tabindex="-1"></a><span class="co"># The basic steps of a stochastic gradient method #</span></span>
<span id="cb6-3"><a href="stochastisches-gradientenverfahren.html#cb6-3" tabindex="-1"></a><span class="co">###################################################</span></span>
<span id="cb6-4"><a href="stochastisches-gradientenverfahren.html#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="stochastisches-gradientenverfahren.html#cb6-5" tabindex="-1"></a>w <span class="op">=</span> ...  <span class="co"># initialize the weight vector</span></span>
<span id="cb6-6"><a href="stochastisches-gradientenverfahren.html#cb6-6" tabindex="-1"></a>eta <span class="op">=</span> ... <span class="co"># choose the learning rate</span></span>
<span id="cb6-7"><a href="stochastisches-gradientenverfahren.html#cb6-7" tabindex="-1"></a>I <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, ..., N]  <span class="co"># the full index set</span></span>
<span id="cb6-8"><a href="stochastisches-gradientenverfahren.html#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="stochastisches-gradientenverfahren.html#cb6-9" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(number_epochs):</span>
<span id="cb6-10"><a href="stochastisches-gradientenverfahren.html#cb6-10" tabindex="-1"></a>    J <span class="op">=</span> shuffle(I)  <span class="co"># shuffle the indices</span></span>
<span id="cb6-11"><a href="stochastisches-gradientenverfahren.html#cb6-11" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> J:</span>
<span id="cb6-12"><a href="stochastisches-gradientenverfahren.html#cb6-12" tabindex="-1"></a>        <span class="co"># compute the gradient of Qj at current w</span></span>
<span id="cb6-13"><a href="stochastisches-gradientenverfahren.html#cb6-13" tabindex="-1"></a>        gradjk <span class="op">=</span> nabla(Q(j, w))  </span>
<span id="cb6-14"><a href="stochastisches-gradientenverfahren.html#cb6-14" tabindex="-1"></a>        <span class="co"># update the w vector</span></span>
<span id="cb6-15"><a href="stochastisches-gradientenverfahren.html#cb6-15" tabindex="-1"></a>        w <span class="op">=</span> w <span class="op">-</span> eta<span class="op">*</span>gradjk</span>
<span id="cb6-16"><a href="stochastisches-gradientenverfahren.html#cb6-16" tabindex="-1"></a>    <span class="cf">if</span> convergence_criterion:</span>
<span id="cb6-17"><a href="stochastisches-gradientenverfahren.html#cb6-17" tabindex="-1"></a>       <span class="cf">break</span></span>
<span id="cb6-18"><a href="stochastisches-gradientenverfahren.html#cb6-18" tabindex="-1"></a><span class="co">###################################################</span></span></code></pre></div>
<p>Die Konvergenz des <em>stochastischen Gradientenabstiegsverfahren</em> als Kombination von <em>stochastischer Approximation</em> und <em>numerischer Optimierung</em> ist gut verstanden. Allgemein und unter bestimmten Voraussetzung lässt sich sagen, dass das stochastische Verfahren ähnlich konvergiert wie das <em>exakte Verfahren</em> mit der Einschränkung, dass die Konvergenz <em>fast sicher</em> stattfindet.</p>
<p>In der Praxis hat sich der Kompromiss etabliert, der anstelle des Gradienten eines einzelnen Punktes <span class="math inline">\(\nabla Q_j(w_k)\)</span>, den Abstieg aus dem Mittelwert über mehrere Samples berechnet, also (wie oben beschrieben)
<span class="math display">\[\begin{equation*}
\frac{1}{N} \sum_{i=1}^N \nabla Q_i(w^k) \approx \frac{1}{|\mathcal J|} \sum_{j\in \mathcal J} \nabla Q_j(w^k).
\end{equation*}\]</span>
Im Algorithmus wird dann anstelle der zufälligen Indices <span class="math inline">\(j \in \{1, \dotsc, N\}\)</span>, über zufällig zusammengestellte Indexmengen <span class="math inline">\(\mathcal J \subset \{1, \dotsc, N\}\)</span> iteriert.</p>
<p>Da die einzelnen Gradienten <span class="math inline">\(\nabla Q_j(w^K)\)</span> unabhängig voneinander berechnet werden können, kann so ein <em>batch</em> Verfahren effizient auf Computern mit mehreren Prozessoren realisiert werden. Die Konvergenztheorie ist nicht wesentlich verschieden vom eigentlichen <em>stochastischen Gradientenabstiegsverfahren</em>, allerdings erscheint die beobachte Konvergenz weniger erratisch, da der Mittelwert statistische Ausreißer ausmitteln kann.</p>
</div>
<div id="konvergenzanalyse" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Konvergenzanalyse<a href="stochastisches-gradientenverfahren.html#konvergenzanalyse" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Wir betrachten den einfachsten Fall wie im obigen Algorithmus beschrieben, dass im <span class="math inline">\(k\)</span>-ten Schritt, die Schätzung
<span class="math display">\[g(x_k, \xi)=g(x_k, i(\xi))=:\nabla Q_{i(\xi)}(x_k)\]</span>
also dass der Gradient von <span class="math inline">\(\frac 1N \nabla \sum Q_i\)</span> geschätzt wird durch den Gradienten der <span class="math inline">\(i(\xi)\)</span>-ten Komponentenfunktion, wobei <span class="math inline">\(i(\xi)\)</span> zufällig aus der Indexmenge <span class="math inline">\(I=\{1, 2, \dotsc, N\}\)</span> gezogen wird.</p>
<div id="sdg-put-it-back" class="JHSAYS">
<p>Im folgenden Beweis wird verwendet werden, dass <em>zurückgelegt</em> wird, also dass im <span class="math inline">\(k\)</span>-ten Schritt alle möglichen Indizes gezogen werden können. Das ist notwendig um zu schlussfolgern, dass
<span class="math display">\[\begin{equation*}
\mathbb E_{i(\xi)} [g(x_k, k_\xi)] = \nabla Q(x_k)
\end{equation*}\]</span>
In der Praxis (und oben im Algorithmus) wir <strong>nicht</strong> zurückgelegt, es gilt also <span class="math inline">\(I_{k+1} = I_k \setminus \{k_\xi\}\)</span>. Der Grund dafür ist, dass gerne gesichert wird, dass auch in wenig Iterationsschritten alle Datenpunkte <em>besucht</em> werden.</p>
</div>
<p>Und die Iteration lautet
<span class="math display">\[\begin{equation*}
x_{k+1} = x_k - \eta_k g(x_k, i(\xi)).
\end{equation*}\]</span></p>
<div class="theorem">
<p><span id="thm:thm-convergence-stoch-grad" class="theorem"><strong>Theorem 4.1  (Konvergenz des stochastischen Gradientenabstiegsverfahren) </strong></span>Sei <span class="math inline">\(Q:=\frac 1N \sum_{i=1}^NQ_i\)</span> zweimal stetig differenzierbar und <em>streng konvex</em> mit <em>Modulus</em> <span class="math inline">\(m&gt;0\)</span> und es gebe eine Konstante <span class="math inline">\(M\)</span> mit <span class="math inline">\(\frac 1N \sum_{i=1}^N \|\nabla Q_i \|_2^2 \leq M\)</span>. Ferner sei
<!-- seien die Funktionen $Q_i$ konvex und es sei -->
<span class="math inline">\(x^*\)</span> das Minimum von <span class="math inline">\(Q\)</span>. Dann konvergiert das einfache stochastische Gradientenabstiegsverfahren mit <span class="math inline">\(\eta_k := \frac{1}{km}\)</span> linear im Erwartungswert des quadrierten Fehlers, d.h. es gilt
<span class="math display">\[\begin{equation*}
a_{k+1} := \frac 12 \mathbb E [\| x_{k+1} - x^*\|^2 ] \leq \frac {C}{k}
\end{equation*}\]</span>
für eine Konstante <span class="math inline">\(C\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-5" class="proof"><em>Proof</em>. </span>Streng konvex mit Modulus <span class="math inline">\(m&gt;0\)</span> bedeutet, dass alle Eigenwerte der Hessematrix <span class="math inline">\(H_Q\)</span> größer als <span class="math inline">\(m\)</span> sind.
<!--Daraus l&auml;sst sich ableiten, dass f&uuml;r alle *subgradienten* $g$ gilt, dass-->
Insbesondere gilt, dass
<span class="math display">\[\begin{equation*}
Q(z) \leq Q(x) + \nabla Q(x)^T(z-x) + \frac12 m \|z-x\|^2
\end{equation*}\]</span>
für alle <span class="math inline">\(z\)</span> und <span class="math inline">\(x\)</span> aus dem Definitionsbereich von <span class="math inline">\(Q\)</span>.</p>
<!-- Aus $Q_i$ konvex, folgt dass $\nabla Q_k (x_k)$ ein Subgradient ist, sodass wir obige Relation in der folgenden Argumentation verwenden k&ouml;nnen. -->
<p>Zunächst erhalten wir aus der Definition der 2-norm, dass
<span class="math display">\[\begin{equation*}
\begin{split}
\frac 12 \|x_{k+1} - x^* \|^2 &amp;=
\frac 12 \|x_{k} - \eta_k \nabla Q_{i(k;\xi)}(x_k) - x^* \|^2 \\
&amp;=
\frac 12 \|x_{k} - x^* \|^2 - \eta_k \nabla Q_{i(k;\xi)}(x_k)^T( x_{k} -x^*) + \eta_k^2 \|\nabla Q_{i(k;\xi)}(x_k)\|^2
\end{split}
\end{equation*}\]</span></p>
<p>Im nächsten Schritt nehmen wir den Erwartungswert dieser Terme. Dabei ist zu beachten, dass auch die <span class="math inline">\(x_k\)</span> zufällig (aus der Sequenz der zufällig gezogenen Richtungen) erzeugt wurden. Dementsprechend müssen wir zwischen <span class="math inline">\(\mathbb E\)</span> (als Erwartungswert bezüglich aller bisherigen zufälligen Ereignisse für <span class="math inline">\(\ell=0, 1, \dotsc, k-1\)</span>) und zwischen <span class="math inline">\(\mathbb E_{i(k;\xi)}\)</span> (was wir im <span class="math inline">\(k\)</span>-ten Schritt bezüglich der aktuellen Auswahl der Richtung erwarten können) unterscheiden.</p>
<p>In jedem Fall ist der Erwartungswert eine lineare Abbildung, sodass wir die einzelnen Terme der Summe separat betrachten können.</p>
<p>Für den Mischterm erhalten wir
<span class="math display">\[\begin{equation*}
\eta_k \mathbb E[ \nabla Q_{i(k;\xi)}(x_k)^T( x_{k} -x^*) ] =
\eta_k \mathbb E\bigl [\mathbb E_{i(k;\xi)}[ \nabla Q_{i(k;\xi)}(x_k)^T( x_{k} -x^*)\,|\, x_k ]\bigr ]
\end{equation*}\]</span>
wobei der innere Term die Erwartung ist unter der Bedingung das <span class="math inline">\(x_k\)</span> eingetreten ist (folgt aus dem Satz der <a href="https://en.wikipedia.org/wiki/Law_of_total_expectation"><em>iterated expectation</em></a>).
Da im inneren Term nur noch die Wahl von <span class="math inline">\(i\)</span> zufällig ist und wegen der Linearität des Erwartungswertes bekommen wir
<span class="math display">\[\begin{equation*}
\begin{split}
\mathbb E_{i(k;\xi)}[ \nabla Q_{i(k;\xi)}(x_k)^T( x_{k} -x^*)\,|\, x_k ] &amp;=
\mathbb E_{i(k;\xi)}[ \nabla Q_{i(k;\xi)}(x_k)^T\,|\, x_k ]( x_{k} -x^*) \\
&amp; = \nabla Q(x_k)^T(x_k - x^*).
\end{split}
\end{equation*}\]</span>
sodass mit der <span class="math inline">\(m\)</span>-Konvexität gilt dass
<span class="math display" id="eq:eqn-m-konvex-grad-est">\[\begin{equation}
\mathbb E[ \nabla Q_{i(k;\xi)}(x_k)^T( x_{k} -x^*) ] \geq m \mathbb E[\|x_k - x^*\|^2];
\tag{4.1}
\end{equation}\]</span>
vergleiche die Übungsaufgabe unten.</p>
<div id="sdg-cnv-independent" class="JHSAYS">
<p>Diese Manipulation mit den Erwartungswerten ist der formale Ausdruck dafür, dass, egal woher das <span class="math inline">\(x_k\)</span> kam, die zufällige Wahl der aktuellen Richtung führt im statistischen Mittel auf <span class="math inline">\(\nabla Q(x_k)\)</span>.</p>
</div>
<p>Mit gleichen Argumenten und der Annahme der Beschränktheit <span class="math inline">\(\|\nabla Q(x)\|^2 &lt; M\)</span>, bekommen wir für die erwartete quadratische Abweichung <span class="math inline">\(a_k\)</span>, dass
<span class="math display">\[\begin{equation*}
\begin{split}
\frac 12 \|x_{k+1} - x^* \|^2 \leq (1-2\eta_k m) \frac 12 \|x_{k} - x^*\| + \frac 12 \eta_k^2 M^2
\end{split}
\end{equation*}\]</span>
beziehungsweise
<span class="math display">\[\begin{equation*}
a_{k+1} \leq (1-2\eta_km)a_k + \frac 12\eta_k^2M.
\end{equation*}\]</span></p>
<p>Insbesondere wegen des konstanten Terms in der Fehlerrekursion, bedarf es bis zur <span class="math inline">\(1/k\)</span>-Konvergenz weiterer Abschätzungen. Wir zeigen induktiv, dass für <span class="math inline">\(\eta_k=\frac{1}{km}\)</span> gilt, dass
<span class="math display">\[\begin{equation*}
a_{k+1} \leq \frac{c}{2k}, \quad c = \max\{\| x_1 - x^*\|^2, \frac{M}{m^2} \}.
\end{equation*}\]</span>
Für <span class="math inline">\(k=1\)</span> (und damit <span class="math inline">\(\eta_k = \frac 1m\)</span>) gilt die Abschätzung da
<span class="math display">\[\begin{equation*}
a_2 \leq (1-2)a_1 + \frac 12 \frac{1}{m^2}M = (-1)\frac 12 \|x_i-x^*\|^2 + \frac 12 \frac{M}{m^2} &lt; \frac{M}{2 m^2} \leq \frac c2.
\end{equation*}\]</span></p>
<p>Für <span class="math inline">\(k\geq 2\)</span> gilt mit <span class="math inline">\(\eta_k = \frac{1}{mk}\)</span>
<span class="math display">\[\begin{equation*}
\begin{split}
a_{k+1} \leq &amp; (1-2m \eta_k)a_k + \frac 12 \eta_k^2 M =  (1-\frac 2k)a_k + \frac 12 \frac{1}{k^2m^2}M \\
\leq&amp;  (1-\frac 2k) \frac c{2k} + \frac c2 \frac{1}{k^2}  =  \frac {k-1}{2k^2}c  = \frac{k^2-1}{k^2}\frac{1}{k+1} \\
\leq&amp; \frac {c}{2(k+1)} \leq \frac{c}{2k}
\end{split}
\end{equation*}\]</span>
sodass der Beweis erbracht ist mit <span class="math inline">\(C:=\frac c2\)</span>.</p>
</div>
<p>Zum Abschluss schätzen wir noch aus der erhaltenen Konvergenzart und –rate,
wie lange iteriert werden muss um den Fehler unter einen vorgegebenen Wert
<span class="math inline">\(\epsilon\)</span> zu bekommen.</p>
<p>Dazu sei <span class="math inline">\(e_{n}\)</span> der Fehler nach der <span class="math inline">\(n\)</span>-ten Iteration und entsprechend <span class="math inline">\(e_0\)</span> der
Fehler zum Startwert.</p>
<ol style="list-style-type: decimal">
<li><p>Für lineare Konvergenz gilt <span class="math inline">\(e_n \leq qe_{n-1} \leq q^n e_0\)</span> und damit
<span class="math display">\[\begin{equation*}
q^n e_0 = e_n&lt; \epsilon \quad \leftrightarrow \quad n &gt; \frac{\log \epsilon -
\log e_0}{\log q}
\end{equation*}\]</span></p></li>
<li><p>Für quadratische Konvergenz folgt aus <span class="math inline">\(e_n \leq ae_{n-1}^2 \leq a^n e_0^{2n}\)</span>, dass
<span class="math display">\[\begin{equation*}
a^n e_0^{2n} = e_n&lt; \epsilon \quad \leftrightarrow \quad n &gt; \frac{\log \epsilon}{\log a + 2\log e_0}
\end{equation*}\]</span></p></li>
<li><p>Für “<span class="math inline">\(1/k\)</span>” mit <span class="math inline">\(e_n\leq \frac {C}{n}\)</span> gilt dann
<span class="math display">\[\begin{equation*}
e_n &lt; \epsilon \leftrightarrow n &gt; \frac{C}{\epsilon}
\end{equation*}\]</span></p></li>
</ol>
<p>Wir lesen ab, dass für lineare Konvergenz der Startwert nur entscheidend
für die Anzahl der Iteration, während für quadratische Konvergenz
<span class="math inline">\(\log a + 2 \log e_0 &lt; 0 \leftrightarrow a &lt; \sqrt e_0\)</span> wichtig ist um
überhaupt Konvergenz zu haben. Abschließend zu bemerken ist dass,
unter den getätigten Annahmen, für den stochastischen Gradientenabstieg der <strong>quadratische Fehler</strong> mit “1/k” konvergiert. Dementsprechend muss entsprechend von <span class="math inline">\(n\sim \frac{1}{\epsilon^2}\)</span> ausgegangen werden.</p>
<div id="rem-bad-conv-sdg" class="JHSAYS">
<p>Diese schlechte Konvergenz ist auch ein Grund dafür, dass das Lernen von
neuronalen Netzen sehr rechenintensiv ist. Abhilfe schaffen hier Algorithmen,
die Richtungsinformationen <em>2. Ordnung</em> einbeziehen (z.B. über ein Momentum
wie im <em>ADAM</em> Algorithmus) sowie der Rückgriff auf <em>low-precision</em>
Arithmetik (was naheliegend ist, wenn kleine <span class="math inline">\(\epsilon\,\)</span>s ohnehin quasi unerreichbar
sind).</p>
</div>
</div>
<div id="übungen-3" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Übungen<a href="stochastisches-gradientenverfahren.html#übungen-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Eine Funktion heißt <span class="math inline">\(L\)</span>-glatt (<em><span class="math inline">\(L\)</span>-smooth</em>) wenn sie stetig
differenzierbar ist und der Gradient <em>Lipschitz</em>-stetig mit Konstante <span class="math inline">\(L\)</span> ist.
Zeigen Sie, dass für ein <span class="math inline">\(L\)</span>-glatte Funktion, die zweimal differenzierbar ist, gilt:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f(y) \leq f(x) + \nabla f(x)^T(y-x) + \frac L2 \|y-x\|^2\)</span> für alle <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span> aus dem Definitionsbereich.</li>
<li><span class="math inline">\(-LI \leq H_f(x) \leq LI\)</span> für alle <span class="math inline">\(x\)</span>, für die Hesse-Matrix
<span class="math inline">\(H_f\)</span> und für “<span class="math inline">\(\leq\)</span>” im Sinne der <em>Loewner-Halbordnung</em> definiter
Matrizen.</li>
</ol></li>
<li><p>Zeigen Sie, dass aus <em>m-Konvexität</em> von <span class="math inline">\(Q\colon \mathbb R^{n}\to \mathbb R^{}\)</span> und <span class="math inline">\(\mathbb E_\xi [g(\xi)] = \nabla Q(x)\)</span> folgt, dass im Minimum <span class="math inline">\(x^*\)</span> von <span class="math inline">\(Q\)</span> gilt, dass
<span class="math display">\[\begin{equation*}
\mathbb E_\xi[g(\xi)^T(x-x^*)] \geq Q(x)-Q(x^*) + \frac m2\|x - x^*\|^2  \geq m\|x - x^*\|^2,
\end{equation*}\]</span>
für alle <span class="math inline">\(x\)</span>.</p></li>
<li><p>((super)-Quadratische Kovergenz für glatte konvexe Funktionen) Sei <span class="math inline">\(f\colon \mathbb R^{n}\to \mathbb R^{}\)</span> konvex und <span class="math inline">\(L\)</span>-glatt und sei
<span class="math inline">\(x^*\)</span> die Lösung von <span class="math inline">\(f(x)\to \min\)</span>. Zeigen Sie, dass
Gradientenverfahren mit der Schrittweite <span class="math inline">\(\frac 1L\)</span> eine Folge <span class="math inline">\(\{x_k\}_{k\in \mathbb N}\subset \mathbb R^{n}\)</span> erzeugt für die gilt
<span class="math display">\[\begin{equation*}
f(x_N)-f(x^*) \leq \frac{L}{2T} \|x_0 - x^*\|^2, \quad N=1, 2, \dotsc .
\end{equation*}\]</span></p></li>
<li><p>Berechnen sie näherungsweise den Gradienten der Beispielfunktion
<span class="math display">\[\begin{equation*}
f(x_1, x_2, x_3) = \sin(x_1) + x_3\cos(x_2) - 2x_2 + x_1^2 + x_2^2 + x_3^2
\end{equation*}\]</span>
im Punkt <span class="math inline">\((x_1, x_2, x_3) = (1, 1, 1)\)</span>,
indem sie die partiellen Ableitungen durch den Differenzenquotienten, z.B.,
<span class="math display">\[\begin{equation*}
\frac{\partial g}{\partial x_2}(1, 1, 1) \approx \frac{g(1, 1+h, 1) - g(1, 1,1)}{h}
\end{equation*}\]</span>
für <span class="math inline">\(h\in\{10^{-3}, 10^{-6}, 10^{-9}, 10^{-12}\}\)</span> berechnen. Berechnen sie auch die Norm der Differenz zum exakten Wert von <span class="math inline">\(\nabla g(1, 1, 1)\)</span> (s.o.) und interpretieren sie die Ergebnisse.</p></li>
</ol>
<p>Hier schon mal ein Codegerüst.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="stochastisches-gradientenverfahren.html#cb7-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="stochastisches-gradientenverfahren.html#cb7-2" tabindex="-1"></a> </span>
<span id="cb7-3"><a href="stochastisches-gradientenverfahren.html#cb7-3" tabindex="-1"></a><span class="kw">def</span> gfun(x):</span>
<span id="cb7-4"><a href="stochastisches-gradientenverfahren.html#cb7-4" tabindex="-1"></a>    <span class="cf">return</span> np.sin(x[<span class="dv">0</span>]) <span class="op">+</span> x[<span class="dv">2</span>]<span class="op">*</span>np.cos(x[<span class="dv">1</span>]) <span class="op">\</span></span>
<span id="cb7-5"><a href="stochastisches-gradientenverfahren.html#cb7-5" tabindex="-1"></a>        <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>x[<span class="dv">1</span>] <span class="op">+</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">\</span></span>
<span id="cb7-6"><a href="stochastisches-gradientenverfahren.html#cb7-6" tabindex="-1"></a>        <span class="op">+</span> x[<span class="dv">2</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb7-7"><a href="stochastisches-gradientenverfahren.html#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="stochastisches-gradientenverfahren.html#cb7-8" tabindex="-1"></a><span class="kw">def</span> gradg(x):</span>
<span id="cb7-9"><a href="stochastisches-gradientenverfahren.html#cb7-9" tabindex="-1"></a>    <span class="cf">return</span> np.array([np.NaN,</span>
<span id="cb7-10"><a href="stochastisches-gradientenverfahren.html#cb7-10" tabindex="-1"></a>                     <span class="op">-</span>x[<span class="dv">2</span>]<span class="op">*</span>np.sin(x[<span class="dv">1</span>]) <span class="op">-</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>x[<span class="dv">1</span>],</span>
<span id="cb7-11"><a href="stochastisches-gradientenverfahren.html#cb7-11" tabindex="-1"></a>                     np.NaN]).reshape((<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb7-12"><a href="stochastisches-gradientenverfahren.html#cb7-12" tabindex="-1"></a></span>
<span id="cb7-13"><a href="stochastisches-gradientenverfahren.html#cb7-13" tabindex="-1"></a><span class="co"># Inkrement</span></span>
<span id="cb7-14"><a href="stochastisches-gradientenverfahren.html#cb7-14" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb7-15"><a href="stochastisches-gradientenverfahren.html#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a href="stochastisches-gradientenverfahren.html#cb7-16" tabindex="-1"></a><span class="co"># der x-wert und das h-Inkrement in der zweiten Komponente</span></span>
<span id="cb7-17"><a href="stochastisches-gradientenverfahren.html#cb7-17" tabindex="-1"></a>xzero <span class="op">=</span> np.ones((<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb7-18"><a href="stochastisches-gradientenverfahren.html#cb7-18" tabindex="-1"></a>xzeroh <span class="op">=</span> xzero <span class="op">+</span> np.array([<span class="dv">0</span>, h, <span class="dv">0</span>]).reshape((<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb7-19"><a href="stochastisches-gradientenverfahren.html#cb7-19" tabindex="-1"></a></span>
<span id="cb7-20"><a href="stochastisches-gradientenverfahren.html#cb7-20" tabindex="-1"></a><span class="co"># partieller Differenzenquotient</span></span>
<span id="cb7-21"><a href="stochastisches-gradientenverfahren.html#cb7-21" tabindex="-1"></a>dgdxtwo <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>h<span class="op">*</span>(gfun(xzeroh) <span class="op">-</span> gfun(xzero))</span>
<span id="cb7-22"><a href="stochastisches-gradientenverfahren.html#cb7-22" tabindex="-1"></a><span class="co"># Alle partiellen Ableitungen ergeben den Gradienten</span></span>
<span id="cb7-23"><a href="stochastisches-gradientenverfahren.html#cb7-23" tabindex="-1"></a>hgrad <span class="op">=</span> np.array([np.NaN, dgdxtwo, np.NaN]).reshape((<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb7-24"><a href="stochastisches-gradientenverfahren.html#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="stochastisches-gradientenverfahren.html#cb7-25" tabindex="-1"></a><span class="co"># Analytisch bestimmter Gradient</span></span>
<span id="cb7-26"><a href="stochastisches-gradientenverfahren.html#cb7-26" tabindex="-1"></a>gradx <span class="op">=</span> gradg(xzero)</span>
<span id="cb7-27"><a href="stochastisches-gradientenverfahren.html#cb7-27" tabindex="-1"></a></span>
<span id="cb7-28"><a href="stochastisches-gradientenverfahren.html#cb7-28" tabindex="-1"></a><span class="co"># Die Differenz in der Norm</span></span>
<span id="cb7-29"><a href="stochastisches-gradientenverfahren.html#cb7-29" tabindex="-1"></a>hdiff <span class="op">=</span> np.linalg.norm((hgrad<span class="op">-</span>gradx)[<span class="dv">1</span>])</span>
<span id="cb7-30"><a href="stochastisches-gradientenverfahren.html#cb7-30" tabindex="-1"></a><span class="co"># bitte alle Kompenenten berechnen</span></span>
<span id="cb7-31"><a href="stochastisches-gradientenverfahren.html#cb7-31" tabindex="-1"></a><span class="co"># und dann die Norm ueber den ganzen Vektor nehmen</span></span>
<span id="cb7-32"><a href="stochastisches-gradientenverfahren.html#cb7-32" tabindex="-1"></a></span>
<span id="cb7-33"><a href="stochastisches-gradientenverfahren.html#cb7-33" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;h=</span><span class="sc">{</span>h<span class="sc">:.2e}</span><span class="ss">: diff in gradient </span><span class="sc">{</span>hdiff<span class="sc">.</span>flatten()[<span class="dv">0</span>]<span class="sc">:.2e}</span><span class="ss">&#39;</span>)</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="iterative-methoden.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ein-nn-beispiel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["NdML.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
