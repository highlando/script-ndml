% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Numerik des Maschinellen Lernens},
  pdfauthor={Jan Heiland},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=purple,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{xcolor}
\definecolor{jhsc}{HTML}{1f57c7}
\newenvironment {JHSAYS} [0] {\begin{quote}\color{jhsc}} {\end{quote}}

\title{Numerik des Maschinellen Lernens}
\author{Jan Heiland}
\date{TU Ilmenau -- Sommersemester 2024}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{vorwort}{%
\chapter*{Vorwort}\label{vorwort}}
\addcontentsline{toc}{chapter}{Vorwort}

Das ist ein Aufschrieb der parallel zur Vorlesung erweitert wird.

Korrekturen und Wünsche immer gerne als \emph{issues} oder \emph{pull requests} ans \href{https://github.com/highlando/script-nmdl}{github-repo}.

\hypertarget{einfuxfchrung}{%
\chapter{Einführung}\label{einfuxfchrung}}

Was sind \emph{Numerische Methoden für Maschinelles Lernen} (ML)?

Kurz gesagt, beim Training eines ML-Modells durchläuft ein Computer Millionen von Anweisungen, die in Form mathematischer Ausdrücke formuliert sind.
Gleiches gilt für die Bewertung eines solchen Modells.
Dann stellen sich Fragen wie \emph{wird es einen Punkt geben, an dem das Training endet?} und \emph{wird das Modell genau sein?}.

Um zu beschreiben, was passiert, und für die spätere Analyse führen wir die allgemeinen Konzepte von

\begin{itemize}
\tightlist
\item
  Algorithmus
\item
  Konsistenz/Genauigkeit
\item
  Stabilität
\item
  Rechenaufwand
\end{itemize}

ein, von denen einige klassische \emph{numerische Analysen} sind.

\hypertarget{was-ist-ein-algorithmus}{%
\section{Was ist ein Algorithmus}\label{was-ist-ein-algorithmus}}

Interessanterweise ist der Begriff \emph{Algorithmus} ähnlich intuitiv und abstrakt. Es bedurfte großer Anstrengungen, um eine allgemeine und prägnante Definition zu finden, die den Anforderungen und Einschränkungen aller Bereiche gerecht wird (von \emph{Kochrezepten} bis zur Analyse von \emph{formalen Sprachen}).

\begin{definition}[Algorithmus]
\protect\hypertarget{def:algorithm}{}\label{def:algorithm}Ein Problemlösungsverfahren wird als \emph{Algorithmus} bezeichnet, wenn und nur wenn es eine \emph{Turing-Maschine} gibt, die dem Verfahren entspricht und die, für jede Eingabe, für die eine Lösung existiert, \emph{anhalten} wird.
\end{definition}

Diese Definition ist in ihrer Allgemeinheit nicht allzu hilfreich - wir haben nicht einmal definiert, was eine Turing-Maschine ist.

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Eine \emph{Turing-Maschine} kann als eine Maschine beschrieben werden, die einen Streifen von Anweisungen liest und auf diesen Streifen schreiben kann. Abhängig davon, was sie liest, kann sie vorwärts bewegen, rückwärts bewegen oder anhalten (wenn der Streifen einen vordefinierten Zustand erreicht hat). Das Schöne daran ist, dass dieses Setup in einen vollständig mathematischen Rahmen gestellt werden kann.

\end{JHSAYS}

Hilfreicher und gebräuchlicher ist es, die Implikationen dieser Definition zu betrachten, um zu überprüfen, ob ein Verfahren zumindest die notwendigen Bedingungen für einen Algorithmus erfüllt

\begin{itemize}
\tightlist
\item
  Der Algorithmus wird durch endlich viele Anweisungen beschrieben (Endlichkeit).
\item
  Jeder Schritt ist \emph{machbar}.
\item
  Der Algorithmus erfordert eine endliche Menge an Speicher.
\item
  Er wird nach endlich vielen Schritten beendet.
\item
  In jedem Schritt ist der nächste Schritt eindeutig definiert (\emph{deterministisch}).
\item
  Für denselben Anfangszustand wird er im selben Endzustand anhalten (\emph{bestimmt}).
\end{itemize}

Somit könnte eine informelle, gute Praxisdefinition eines Algorithmus sein

\begin{definition}[Algorithmus -- informell]
\protect\hypertarget{def:info-algorithm}{}\label{def:info-algorithm}Ein Verfahren aus endlich vielen Anweisungen wird als \emph{Algorithmus} bezeichnet, wenn es eine bestimmte Lösung -- falls sie existiert -- zu einem Problem in endlich vielen Schritten berechnet.
\end{definition}

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Beachten Sie, wie einige Eigenschaften (wie endlich viele Anweisungen) a priori angenommen werden.

\end{JHSAYS}

Als noch informelleren Verweis auf Algorithmen werden wir die Begriffe \textbf{\emph{(numerische) Methode}} oder \textbf{\emph{Schema}} verwenden, um ein Verfahren durch Auflistung seiner zugrundeliegenden Ideen und Unterprozeduren anzusprechen, wobei \emph{Algorithmus} sich auf eine spezifische Realisierung einer \emph{Methode} bezieht.

Weiterhin unterscheiden wir

\begin{itemize}
\tightlist
\item
  \emph{direkte} Methoden -- die die Lösung exakt berechnen (wie die Lösung eines linearen Systems durch \emph{Gauß-Elimination}) und
\item
  \emph{iterative} Methoden -- die iterativ eine Folge von Annäherungen an die Lösung berechnen (wie die Berechnung von Wurzeln mit einem \emph{Newton-Schema}).
\end{itemize}

\hypertarget{konsistenz-stabilituxe4t-genauigkeit}{%
\section{Konsistenz, Stabilität, Genauigkeit}\label{konsistenz-stabilituxe4t-genauigkeit}}

Für die Analyse numerischer Methoden werden allgemein die folgenden Begriffe verwendet:

\begin{definition}[Konsistenz]
\protect\hypertarget{def:consistency}{}\label{def:consistency}Wenn ein Algorithmus in exakter Arithmetik die Lösung des Problems mit einer gegebenen Genauigkeit berechnet, wird er als \emph{konsistent} bezeichnet.
\end{definition}

\begin{definition}[Stabilität (informell)]
\protect\hypertarget{def:stability}{}\label{def:stability}Wenn die Ausgabe eines Algorithmus kontinuierlich von Unterschieden in der Eingabe und kontinuierlich von Unterschieden in den Anweisungen abhängt, dann wird der Algorithmus als \emph{stabil} bezeichnet.
\end{definition}

Die \emph{Unterschiede in den Anweisungen} sind typischerweise auf Rundungsfehler zurückzuführen, wie sie in \emph{ungenauer Arithmetik} auftreten.

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Man könnte sagen, dass ein Algorithmus konsistent ist, wenn \emph{er das Richtige tut} und dass er stabil ist, \emph{wenn er trotz aller Arten von kleinen Ungenauigkeiten funktioniert}. Wenn ein Algorithmus konsistent und stabil ist, wird er oft als \emph{konvergent} bezeichnet, um auszudrücken, dass er schließlich die Lösung auch in ungenauer Arithmetik berechnen wird.

\end{JHSAYS}

Beachten Sie, dass Begriffe wie

\begin{itemize}
\tightlist
\item
  \emph{Genauigkeit} -- wie nahe die berechnete Ausgabe der tatsächlichen Lösung kommt oder
\item
  \emph{Konvergenz} -- wie schnell (typischerweise in Bezug auf den Rechenaufwand) der Algorithmus sich der tatsächlichen Lösung nähert
\end{itemize}

keine intrinsischen Eigenschaften eines Algorithmus sind, da sie von dem zu lösenden Problem abhängen.
Man kann jedoch von \emph{Ordnungskonsistenz} eines Algorithmus sprechen, um die erwartete Genauigkeit für eine Klasse von Problemen zu spezifizieren, und einen Algorithmus als konvergent einer bestimmten Ordnung bezeichnen, wenn er auch stabil ist.

\hypertarget{rechenkomplexituxe4t}{%
\section{Rechenkomplexität}\label{rechenkomplexituxe4t}}

Die \emph{Rechenkomplexität} eines Algorithmus ist sowohl theoretisch (um abzuschätzen, wie der Aufwand mit beispielsweise der Größe des Problems skaliert) als auch praktisch (um zu sagen, wie lange das Verfahren dauern wird und welche Kosten in Bezug auf CPU-Zeit oder Speichernutzung es generieren wird) wichtig.

Typischerweise wird die Komplexität durch Zählen der elementaren Operationen gemessen, oft als \emph{FLOP}s bezeichnet, was für \emph{floating point operations} steht.
Um die Algorithmen in Bezug auf Komplexität versus Problemgröße zu klassifizieren, sind die folgenden Funktionsklassen hilfreich

\begin{definition}[Landau-Symbole oder große O-Notation]
\protect\hypertarget{def:landau-symbs}{}\label{def:landau-symbs}Sei \(g\colon \mathbb R^{} \to \mathbb R^{}\) und \(a\in\mathbb R^{} \cup \{-\infty, +\infty\}\). Dann sagen wir für eine Funktion \(f\colon \mathbb R \to \mathbb R^{}\), dass \(f\in O(g)\), wenn
\begin{equation*}
\limsup_{x\to a} \frac{|f(x)|}{|g(x)|} < \infty
\end{equation*}
und dass \(f\in o(g)\), wenn
\begin{equation*}
\limsup_{x\to a} \frac{|f(x)|}{|g(x)|} = 0.
\end{equation*}
\end{definition}

Der Sinn und die Funktionalität dieser Konzepte wird vielleicht deutlich, wenn man sich die typischen Anwendungen ansieht:

\begin{itemize}
\tightlist
\item
  Wenn \(h> 0\) ein Diskretisierungsparameter ist und, sagen wir, \(e(h)\) der Diskretisierungsfehler ist, dann könnten wir sagen, dass \(e(h) = O(h^2)\), wenn \emph{asymptotisch}, d.h. für immer kleinere \(h\) -- der Fehler mindestens so schnell wie \(h^2\) gegen \(0\) geht.
\item
  Wenn \(C(n)\) die Komplexität eines Algorithmus für eine Problemgröße \(n\) ist, dann könnten wir sagen, dass \(C(n) = O(n)\), um auszudrücken, dass die Komplexität \emph{asymptotisch}, d.h. für immer größere \(n\), mit derselben Geschwindigkeit wie die Problemgröße wächst.
\end{itemize}

Leider ist die übliche Verwendung der Landau-Symbole etwas nachlässig.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Das oft verwendete ``\(=\)''-Zeichen ist informell und keineswegs eine Gleichheit.
\item
  Was das Limit \(a\) ist, wird kaum jemals explizit erwähnt, aber glücklicherweise ist es in der Regel aus dem Kontext klar.
\end{enumerate}

Als Beispiel betrachten wir zwei verschiedene Wege, ein Polynom \(p\) vom Grad \(n\) an der Abszisse \(x\) zu bewerten, basierend auf den zwei äquivalenten Darstellungen
\begin{equation*}
\begin{split}
p(x) &= a_0 + a_1x +  a_2x^2+ \dotsm + a_nx^n \\
     &= a_0 + x(a_1 + x(a_2 + \dotsm +x(a_{n-1} + a_nx) \dotsm ))
\end{split}
\end{equation*}

Für eine direkte Implementierung der ersten Darstellung erhalten wir

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}Berechnung von p(x) in Standarddarstellung}
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}                                      \CommentTok{\# Beispielwert für n}
\NormalTok{ais }\OperatorTok{=}\NormalTok{ [(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{**}\NormalTok{k}\OperatorTok{*}\DecValTok{1}\OperatorTok{/}\NormalTok{k }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{+}\DecValTok{2}\NormalTok{)]  }\CommentTok{\# Liste der Beispielkoeffizienten}
\NormalTok{x }\OperatorTok{=} \DecValTok{5}                                       \CommentTok{\# Ein Beispielwert für x}
\NormalTok{cpx }\OperatorTok{=}\NormalTok{ ais[}\DecValTok{0}\NormalTok{]                                }\CommentTok{\# der Fall k=0}
\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{    cpx }\OperatorTok{=}\NormalTok{ cpx }\OperatorTok{+}\NormalTok{ ais[k}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\NormalTok{ x}\OperatorTok{**}\NormalTok{(k}\OperatorTok{+}\DecValTok{1}\NormalTok{)         }\CommentTok{\# der Beitrag des k{-}ten Schritts}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}x=}\SpecialCharTok{\{x\}}\SpecialStringTok{: p(x)=}\SpecialCharTok{\{}\NormalTok{cpx}\SpecialCharTok{:.4f\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)             }\CommentTok{\# Ausgabe des Ergebnisses}
\end{Highlighting}
\end{Shaded}

Im \(k\)-ten Schritt benötigt der Algorithmus eine Addition (wenn wir auch die Initialisierung als Addition zählen) und \(k\) Multiplikationen. Das ergibt eine Gesamtkomplexität von
\begin{equation*}
C(n) = \sum_{k=0}^n(1+k) = n+1 + \frac{n(n-1)}{2} = 1 + \frac n2 + \frac{n^2}2 = O(n^2)
\end{equation*}

Für die zweite Darstellung können wir das sogenannte \emph{Horner-Schema} implementieren, das lauten würde

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}Berechnung von p(x) mit dem Horner{-}Schema}
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}                                      \CommentTok{\# Beispielwert für n}
\NormalTok{ais }\OperatorTok{=}\NormalTok{ [(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{**}\NormalTok{k}\OperatorTok{*}\DecValTok{1}\OperatorTok{/}\NormalTok{k }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{+}\DecValTok{2}\NormalTok{)]  }\CommentTok{\# Liste der Beispielkoeffizienten}
\NormalTok{x }\OperatorTok{=} \DecValTok{5}                                       \CommentTok{\# Ein Beispielwert für x}
\NormalTok{cpx }\OperatorTok{=}\NormalTok{ ais[n]                                }\CommentTok{\# der Fall k=n}
\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{reversed}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n)):                }
\NormalTok{    cpx }\OperatorTok{=}\NormalTok{ ais[k] }\OperatorTok{+}\NormalTok{ x}\OperatorTok{*}\NormalTok{cpx                    }\CommentTok{\# der Beitrag des k{-}ten Schritts}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}x=}\SpecialCharTok{\{x\}}\SpecialStringTok{: p(x)=}\SpecialCharTok{\{}\NormalTok{cpx}\SpecialCharTok{:.4f\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)             }\CommentTok{\# Ausgabe des Ergebnisses}
\end{Highlighting}
\end{Shaded}

Insgesamt benötigt dieses Schema \(n+1\) Additionen und \(n\) Multiplikationen, d.h. \(2n+1\) FLOPs, so dass wir sagen können, dass \emph{dieser Algorithmus \(O(n)\) ist}.

\hypertarget{uxfcbungen}{%
\section{Übungen}\label{uxfcbungen}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Vergleichen Sie die beiden Implementierungen zur Bewertung eines Polynoms, indem Sie die Komplexität als Funktion von \(n\) darstellen und die benötigte CPU-Zeit für eine Beispielbewertung im Vergleich zu \(n\) messen und darstellen.
\end{enumerate}

Weiterführende Literatur:

\begin{itemize}
\tightlist
\item
  \href{https://de.wikipedia.org/wiki/Algorithmus\#Definition}{wikipedia:Algorithmus}
\end{itemize}

\hypertarget{fehler-und-konditionierung}{%
\chapter{Fehler und Konditionierung}\label{fehler-und-konditionierung}}

\def\kij{(\kappa_{A,x})_{ij}}

Berechnungen auf einem Computer verursachen unvermeidlich Fehler, und die Effizienz oder Leistung von Algorithmen ist immer das Verhältnis von Kosten zu Genauigkeit.
Zum Beispiel:

\begin{itemize}
\item
  Allein durch Betrachtung von Rundungsfehlern kann die Genauigkeit einfach und signifikant verbessert werden, indem auf Hochpräzisionsarithmetik zurückgegriffen wird, was jedoch höhere Speicheranforderungen und eine höhere Rechenlast mit sich bringt.
\item
  In iterativen Verfahren können Speicher und Rechenaufwand leicht gespart werden, indem die Iteration in einem frühen Stadium gestoppt wird - auf Kosten einer weniger genauen Lösungsapproximation.
\end{itemize}

\leavevmode\hypertarget{rem-accu-iter}{}%
\begin{JHSAYS}
Beide, irgendwie trivialen Beobachtungen sind grundlegende Bestandteile des Trainings neuronaler Netzwerke. Erstens wurde beobachtet, dass Niedrigpräzisionsarithmetik Rechenkosten sparen kann, mit nur geringen Auswirkungen auf die Genauigkeit. Zweitens ist das Training ein iterativer Prozess mit oft langsamer Konvergenz, sodass der richtige Zeitpunkt für einen vorzeitigen Abbruch des Trainings entscheidend ist.

\end{JHSAYS}

\begin{definition}[Absolute und relative Fehler]
\protect\hypertarget{def:errors}{}\label{def:errors}Sei \(x\in\mathbb R^{}\) die interessierende Größe und \(\tilde x \in \mathbb R^{}\) eine Annäherung daran. Dann wird der \emph{absolute Fehler} definiert als \(|\delta x|:=|\tilde x- x|\) und der \emph{relative Fehler} als \(\frac{|\delta x|}{|x|}=\frac{|\tilde x- x|}{|x|}\).
\end{definition}

\leavevmode\hypertarget{rem-rel-abs-err}{}%
\begin{JHSAYS}
Generell wird der relative Fehler bevorzugt, da er den gemessenen Fehler in den richtigen Bezug setzt. Zum Beispiel kann ein absoluter Fehler von \(10\) km/h je nach Kontext groß oder klein sein. Andererseits erfordert der relative Fehler die Kenntnis des tatsächlichen Werts und die Division durch einen Wert nahe \(0\) kann die Fehlerschätzung verstärken.

\end{JHSAYS}

Als Nächstes definieren wir die \emph{Kondition} eines Problems \(A\) und analog eines Algorithmus (der das Problem löst). Dafür lassen wir \(x\) einen Parameter/Eingabe des Problems sein und \(y=A(x)\) die entsprechende Lösung/Ausgabe. Die Kondition ist ein Maß dafür, inwieweit eine Änderung \(x+\delta x\) in der Eingabe die resultierende relative Änderung in der Ausgabe beeinflusst. Dafür betrachten wir
\begin{equation*}
\delta y = \tilde y - y = A(\tilde x) - A(x) = A(x+\delta x) - A(x)
\end{equation*}
welches nach Division durch \(y=A(x)\) und Erweiterung durch \(x\,\delta x\) wird zu
\begin{equation*}
\frac{\delta y}{y} = \frac{A(x+\delta x)-A(x)}{\delta x}\frac{x}{A(x)}\frac{\delta x}{x}.
\end{equation*}
Für infinitesimal kleine \(\delta x\) wird der Differenzenquotient \(\frac{A(x+\delta x)-A(x)}{\delta x}\) zur Ableitung \(\frac{\partial A}{\partial x}(x)\), so dass wir die Kondition des Problems/Algorithmus bei \(x\) abschätzen können durch
\begin{equation}\label{eq:eqn-scalar-cond}
\frac{|\delta y|}{|y|} \leq |\frac{\partial A}{\partial x}(x)|\frac{|x|}{|A(x)|}\frac{|\delta x|}{|x|}=:\kappa_{A,x}\frac{|\delta x|}{|x|}.
\end{equation}
und nennen \(\kappa_{A,x}\) die Konditionszahl.

Für vektorwertige Probleme/Algorithmen können wir die Konditionszahl darüber definieren, wie eine Differenz in der \(j\)-ten Eingabekomponente \(x_j\) die \(i\)-te Komponente \(y_i=A_i(x)\) der Ausgabe beeinflusst.

\begin{definition}[Konditionszahl]
\protect\hypertarget{def:condition}{}\label{def:condition}Für ein Problem/Algorithmus \(A\colon \mathbb R^{n}\to \mathbb R^{m}\) nennen wir
\begin{equation*}
(\kappa_{A,x})_{ij} := \frac{\partial A_i}{\partial x_j}(x) \frac{x_j}{A_i(x)}
\end{equation*}
die partielle \emph{Konditionszahl} des Problems. Ein Problem wird als \emph{gut konditioniert} bezeichnet, wenn \(|(\kappa_{A,x})_{ij}|\approx 1\) und als \emph{schlecht konditioniert}, wenn \(|(\kappa_{A,x})_{ij}\gg 1\), für alle \(i=1,\dotsc,m\) und \(j=1,\dotsc,m\).
\end{definition}

\leavevmode\hypertarget{rem-vector-valued-cond}{}%
\begin{JHSAYS}
Anstatt die skalaren Komponentenfunktionen von \(A\colon \mathbb R^{n} \to \mathbb R^{m}\) zu verwenden, kann man die Berechnungen, die zu \eqref{eq:eqn-scalar-cond} geführt haben, mit vektorwertigen Größen in den entsprechenden Normen wiederholen.

\end{JHSAYS}

\hypertarget{uxfcbungen-1}{%
\section{Übungen}\label{uxfcbungen-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Leiten Sie die \emph{Konditionszahl} wie in \eqref{eq:eqn-scalar-cond} für eine vektorwertige Funktion \(A\colon \mathbb R^{n} \to \mathbb R^{m}\) ab. Wo spielt eine Matrixnorm eine Rolle?
\item
  Leiten Sie die Konditionszahl einer invertierbaren Matrix \(M\) ab, d.h. die Kondition des Problems \(x\to y = M^{-1}x\), nach demselben Verfahren. Wo spielt die Matrixnorm eine Rolle?
\end{enumerate}

\hypertarget{referenzen}{%
\chapter*{Referenzen}\label{referenzen}}
\addcontentsline{toc}{chapter}{Referenzen}

\end{document}
