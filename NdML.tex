% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Numerik des Maschinellen Lernens},
  pdfauthor={Jan Heiland},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=purple,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{xcolor}
\definecolor{jhsc}{HTML}{1f57c7}
\newenvironment {JHSAYS} [0] {\begin{quote}\color{jhsc}} {\end{quote}}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {}%
  {\par}

\title{Numerik des Maschinellen Lernens}
\author{Jan Heiland}
\date{TU Ilmenau -- Sommersemester 2024}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{vorwort}{%
\chapter*{Vorwort}\label{vorwort}}
\addcontentsline{toc}{chapter}{Vorwort}

Das ist ein Aufschrieb der parallel zur Vorlesung erweitert wird.

Korrekturen und Wünsche immer gerne als \emph{issues} oder \emph{pull requests} ans \href{https://github.com/highlando/script-ndml}{github-repo}.

\hypertarget{einfuxfchrung}{%
\chapter{Einführung}\label{einfuxfchrung}}

Was sind \emph{Numerische Methoden für Maschinelles Lernen} (ML)?

Kurz gesagt, beim Training eines ML-Modells durchläuft ein Computer Millionen von Anweisungen, die in Form mathematischer Ausdrücke formuliert sind. Gleiches gilt für die Bewertung eines solchen Modells.
Dann stellen sich Fragen wie \emph{wird es einen Punkt geben, an dem das Training endet?} und \emph{wird das Modell genau sein?}.

Um zu beschreiben, was passiert, und für die spätere Analyse führen wir die allgemeinen Konzepte von

\begin{itemize}
\tightlist
\item
  Algorithmus
\item
  Konsistenz/Genauigkeit
\item
  Stabilität
\item
  Rechenaufwand
\end{itemize}

ein, von denen einige klassische \emph{numerische Analysis} sind.

\hypertarget{was-ist-ein-algorithmus}{%
\section{Was ist ein Algorithmus}\label{was-ist-ein-algorithmus}}

Interessanterweise ist der Begriff \emph{Algorithmus} zugleich intuitiv und abstrakt. Es bedurfte großer Anstrengungen, um eine allgemeine und wohlgestellte Definition zu finden, die den Anforderungen und Einschränkungen aller Bereiche gerecht wird (von \emph{Kochrezepten} bis zur Analyse von \emph{formalen Sprachen}).

\begin{definition}[Algorithmus]
\protect\hypertarget{def:algorithm}{}\label{def:algorithm}Ein Problemlösungsverfahren wird als \emph{Algorithmus} bezeichnet, genau dann wenn es eine \emph{Turing-Maschine} gibt, die dem Verfahren entspricht und die, für jede Eingabe, für die eine Lösung existiert, \emph{anhalten} wird.
\end{definition}

Diese Definition ist in ihrer Allgemeinheit nicht allzu hilfreich - wir haben noch nicht einmal definiert, was eine Turing-Maschine ist.

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Eine \emph{Turing-Maschine} kann als eine Maschine beschrieben werden, die ein Band von Anweisungen liest und auf dieses Band schreiben kann. Abhängig davon, was sie liest, kann sie vorwärts bewegen, rückwärts bewegen oder anhalten (wenn das Band einen vordefinierten Zustand erreicht hat). Das Schöne daran ist, dass dieses Setup in einen vollständig mathematischen Rahmen gestellt werden kann.

\end{JHSAYS}

Hilfreicher und gebräuchlicher ist es, die Implikationen dieser Definition zu betrachten, um zu überprüfen, ob ein Verfahren zumindest die notwendigen Bedingungen für einen Algorithmus erfüllt

\begin{itemize}
\tightlist
\item
  Der Algorithmus wird durch endlich viele Anweisungen beschrieben (Endlichkeit).
\item
  Jeder Schritt ist \emph{durchführbar}.
\item
  Der Algorithmus erfordert eine endliche Menge an Speicher.
\item
  Er wird nach endlich vielen Schritten beendet.
\item
  In jedem Schritt ist der nächste Schritt eindeutig definiert (\emph{Determiniertheit}).
\item
  Für denselben Anfangszustand wird er im selben Endzustand anhalten (\emph{Bestimmtheit}).
\end{itemize}

Somit könnte eine informelle, gute Praxisdefinition eines Algorithmus sein

\begin{definition}[Algorithmus -- informell]
\protect\hypertarget{def:info-algorithm}{}\label{def:info-algorithm}Ein Verfahren aus endlich vielen Anweisungen wird als \emph{Algorithmus} bezeichnet, wenn es eine bestimmte Lösung -- falls sie existiert -- zu einem Problem in endlich vielen Schritten berechnet.
\end{definition}

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Beachten Sie, wie einige Eigenschaften (wie endlich viele Anweisungen) a priori angenommen werden.

\end{JHSAYS}

Als informellere Verweise auf Algorithmen werden wir die Begriffe \textbf{\emph{(numerische) Methode}} oder \textbf{\emph{Schema}} verwenden, um ein Verfahren durch Auflistung seiner zugrundeliegenden Ideen und Unterprozeduren anzusprechen, wobei \emph{Algorithmus} sich auf eine spezifische Realisierung einer \emph{Methode} bezieht.

Weiterhin unterscheiden wir

\begin{itemize}
\tightlist
\item
  \emph{direkte} Methoden -- die die Lösung exakt berechnen (wie die Lösung eines linearen Systems durch \emph{Gauß-Elimination}) und
\item
  \emph{iterative} Methoden -- die iterativ eine Folge von Annäherungen an die Lösung berechnen (wie die Berechnung von Wurzeln mit einem \emph{Newton-Schema}).
\end{itemize}

\hypertarget{konsistenz-stabilituxe4t-genauigkeit}{%
\section{Konsistenz, Stabilität, Genauigkeit}\label{konsistenz-stabilituxe4t-genauigkeit}}

Für die Analyse numerischer Methoden werden allgemein die folgenden Begriffe verwendet:

\begin{definition}[Konsistenz]
\protect\hypertarget{def:consistency}{}\label{def:consistency}Wenn ein Algorithmus in exakter Arithmetik die Lösung des Problems mit einer gegebenen Genauigkeit berechnet, wird er als \emph{konsistent} bezeichnet.
\end{definition}

\begin{definition}[Stabilität (informell)]
\protect\hypertarget{def:stability}{}\label{def:stability}Wenn die Ausgabe eines Algorithmus kontinuierlich von Unterschieden in der Eingabe und kontinuierlich von Unterschieden in den Anweisungen abhängt, dann wird der Algorithmus als \emph{stabil} bezeichnet.
\end{definition}

Die \emph{Unterschiede in den Anweisungen} sind typischerweise auf Rundungsfehler zurückzuführen, wie sie in \emph{ungenauer Arithmetik} (oft auch als \emph{Gleitkommaarithmetik} bezeichnet) auftreten.

\leavevmode\hypertarget{rem-coors}{}%
\begin{JHSAYS}
Man könnte sagen, dass ein Algorithmus konsistent ist, wenn \emph{er das Richtige tut} und dass er stabil ist, \emph{wenn er trotz beliebiger kleiner Ungenauigkeiten funktioniert}. Wenn ein Algorithmus konsistent und stabil ist, wird er oft als \emph{konvergent} bezeichnet, um auszudrücken, dass er schließlich die Lösung auch in ungenauer Arithmetik berechnen wird.

\end{JHSAYS}

Beachten Sie, dass Begriffe wie

\begin{itemize}
\tightlist
\item
  \emph{Genauigkeit} -- wie nahe die berechnete Ausgabe der tatsächlichen Lösung kommt oder
\item
  \emph{Konvergenz} -- wie schnell (typischerweise in Bezug auf den Rechenaufwand) der Algorithmus sich der tatsächlichen Lösung nähert
\end{itemize}

keine intrinsischen Eigenschaften eines Algorithmus sind, da sie von dem zu lösenden Problem abhängen.
Man kann jedoch von \emph{Konsistenzordnung} eines Algorithmus sprechen, um die erwartete Genauigkeit für eine Klasse von Problemen zu spezifizieren, und einen Algorithmus als konvergent einer bestimmten Ordnung bezeichnen, wenn er zusätzlich stabil ist.

\hypertarget{rechenkomplexituxe4t}{%
\section{Rechenkomplexität}\label{rechenkomplexituxe4t}}

Die \emph{Rechenkomplexität} eines Algorithmus ist sowohl theoretisch (um abzuschätzen, wie der Aufwand mit beispielsweise der Größe des Problems skaliert) als auch praktisch (um zu sagen, wie lange das Verfahren dauern wird und welche Kosten in Bezug auf CPU-Zeit oder Speichernutzung es generieren wird) wichtig.

Typischerweise wird die Komplexität durch Zählen der elementaren Operationen gemessen -- wir werden stets die Ausführung einer Grundrechenart als eine Operation zählen.

\leavevmode\hypertarget{rem-flops}{}%
\begin{JHSAYS}
Die Definition einer \emph{elementaren Operation} auf einem Computer ist nicht universal, da viele Faktoren hier reinspielen. Gerne werden \emph{FLOP}
s angeführt, was für \emph{floating point operations} steht. Allerdings ist es wiederum sehr verschieden auf verschiedenen Prozessoren wieviele FLOPs für eine Multiplikation oder Addition gebraucht werden.

\end{JHSAYS}

Um die Algorithmen in Bezug auf Komplexität versus Problemgröße zu klassifizieren, sind die folgenden Funktionsklassen hilfreich

\begin{definition}[Landau-Symbole oder große O-Notation]
\protect\hypertarget{def:landau-symbs}{}\label{def:landau-symbs}Sei \(g\colon \mathbb R^{} \to \mathbb R^{}\) und \(a\in\mathbb R^{} \cup \{-\infty, +\infty\}\). Dann sagen wir für eine Funktion \(f\colon \mathbb R \to \mathbb R^{}\), dass \(f\in O(g)\), wenn
\begin{equation*}
\limsup_{x\to a} \frac{|f(x)|}{|g(x)|} < \infty
\end{equation*}
und dass \(f\in o(g)\), wenn
\begin{equation*}
\limsup_{x\to a} \frac{|f(x)|}{|g(x)|} = 0.
\end{equation*}
\end{definition}

Der Sinn und die Funktionalität dieser Konzepte wird vielleicht deutlich, wenn man sich die typischen Anwendungen ansieht:

\begin{itemize}
\tightlist
\item
  Wenn \(h> 0\) ein Diskretisierungsparameter ist und, sagen wir, \(e(h)\) der Diskretisierungsfehler ist, dann könnten wir sagen, dass \(e(h) = O(h^2)\), wenn \emph{asymptotisch}, d.h. für immer kleinere \(h\), der Fehler mindestens so schnell wie \(h^2\) gegen \(0\) geht.
\item
  Wenn \(C(n)\) die Komplexität eines Algorithmus für eine Problemgröße \(n\) ist, dann könnten wir sagen, dass \(C(n) = O(n)\), um auszudrücken, dass die Komplexität \emph{asymptotisch}, d.h. für immer größere \(n\), mit derselben Geschwindigkeit wie die Problemgröße wächst.
\end{itemize}

Leider ist die übliche Verwendung der Landau-Symbole etwas unpräzise.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Das oft verwendete ``\(=\)''-Zeichen ist informell und keineswegs eine Gleichheit.
\item
  Was der Grenzwert \(a\) ist, wird selten explizit erwähnt, aber glücklicherweise ist es in der Regel aus dem Kontext klar.
\end{enumerate}

Als Beispiel betrachten wir zwei verschiedene Wege, ein Polynom \(p\) vom Grad \(n\) an der Abszisse \(x\) auszuwerten, basierend auf den zwei äquivalenten Darstellungen
\begin{equation*}
\begin{split}
p(x) &= a_0 + a_1x +  a_2x^2+ \dotsm + a_nx^n \\
     &= a_0 + x(a_1 + x(a_2 + \dotsm +x(a_{n-1} + a_nx) \dotsm ))
\end{split}
\end{equation*}

Für eine direkte Implementierung der ersten Darstellung erhalten wir die Algorithmen

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}Berechnung von p(x) in Standarddarstellung}
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}                                      \CommentTok{\# Beispielwert für n}
\NormalTok{ais }\OperatorTok{=}\NormalTok{ [(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{**}\NormalTok{k}\OperatorTok{*}\DecValTok{1}\OperatorTok{/}\NormalTok{k }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{+}\DecValTok{2}\NormalTok{)]  }\CommentTok{\# Liste der Beispielkoeffizienten}
\NormalTok{x }\OperatorTok{=} \DecValTok{5}                                       \CommentTok{\# Ein Beispielwert für x}
\NormalTok{cpx }\OperatorTok{=}\NormalTok{ ais[}\DecValTok{0}\NormalTok{]                                }\CommentTok{\# der Fall k=0}
\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{    cpx }\OperatorTok{=}\NormalTok{ cpx }\OperatorTok{+}\NormalTok{ ais[k}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\NormalTok{ x}\OperatorTok{**}\NormalTok{(k}\OperatorTok{+}\DecValTok{1}\NormalTok{)         }\CommentTok{\# der Beitrag des k{-}ten Schritts}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}x=}\SpecialCharTok{\{x\}}\SpecialStringTok{: p(x)=}\SpecialCharTok{\{}\NormalTok{cpx}\SpecialCharTok{:.4f\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)             }\CommentTok{\# Ausgabe des Ergebnisses}
\end{Highlighting}
\end{Shaded}

Im \(k\)-ten Schritt benötigt der Algorithmus eine Addition (wenn wir auch die Initialisierung als Addition zählen) und \(k\) Multiplikationen. Das ergibt eine Gesamtkomplexität von
\begin{equation*}
C(n) = \sum_{k=0}^n(1+k) = n+1 + \frac{n(n-1)}{2} = 1 + \frac n2 + \frac{n^2}2 = O(n^2)
\end{equation*}

Für die zweite Darstellung können wir das sogenannte \emph{Horner-Schema} implementieren, das lauten würde

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}Berechnung von p(x) mit dem Horner{-}Schema}
\CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}                                      \CommentTok{\# Beispielwert für n}
\NormalTok{ais }\OperatorTok{=}\NormalTok{ [(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{**}\NormalTok{k}\OperatorTok{*}\DecValTok{1}\OperatorTok{/}\NormalTok{k }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{+}\DecValTok{2}\NormalTok{)]  }\CommentTok{\# Liste der Beispielkoeffizienten}
\NormalTok{x }\OperatorTok{=} \DecValTok{5}                                       \CommentTok{\# Ein Beispielwert für x}
\NormalTok{cpx }\OperatorTok{=}\NormalTok{ ais[n]                                }\CommentTok{\# der Fall k=n}
\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{reversed}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n)):                }
\NormalTok{    cpx }\OperatorTok{=}\NormalTok{ ais[k] }\OperatorTok{+}\NormalTok{ x}\OperatorTok{*}\NormalTok{cpx                    }\CommentTok{\# der Beitrag des k{-}ten Schritts}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}x=}\SpecialCharTok{\{x\}}\SpecialStringTok{: p(x)=}\SpecialCharTok{\{}\NormalTok{cpx}\SpecialCharTok{:.4f\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)             }\CommentTok{\# Ausgabe des Ergebnisses}
\end{Highlighting}
\end{Shaded}

Insgesamt benötigt dieses Schema \(n+1\) Additionen und \(n\) Multiplikationen, d.h. \(2n+1\) FLOPs, so dass wir sagen können, dass \emph{dieser Algorithmus \(O(n)\) ist}.

\hypertarget{literatur}{%
\section{Literatur}\label{literatur}}

\begin{itemize}
\tightlist
\item
  (Nocedal and Wright \protect\hyperlink{ref-NocW06}{2006}): Ein gut lesbares Buch zur Optimierung.
\end{itemize}

\hypertarget{uxfcbungen}{%
\section{Übungen}\label{uxfcbungen}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Vergleichen Sie die beiden Implementierungen zur Auswertung eines Polynoms, indem Sie die Komplexität als Funktion von \(n\) darstellen und die benötigte CPU-Zeit für eine Beispielauswertung im Vergleich zu \(n\) messen und darstellen.
\item
  Zeigen Sie, dass es für \(f\in O(g)\) mit \(f\geq 0\) und \(g> 0\) eine Konstante \(C\) gibt, sodass \(f(n)=h(n) + Cg(n)\) mit \(h\in o(g)\). \emph{Bemerkung: diese Relation ist die Rechtfertigung für die eigentlich inkorrekte Schreibweise \(f=O(g)\)}.
\item
  Ermitteln Sie experimentell \emph{die Ordnung} (d.h. den Exponent \(x\) in \(O(n^x)\)) und \emph{die Konstante} \(C\) (s.o.) für die Laufzeit \(t(n)\) der in \texttt{scipy.linalg.cholesky} implementierten Cholesky Zerlegung der Bandmatrix \texttt{A\_n} aus dem folgenden Code Beispiel
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.linalg }\ImportTok{import}\NormalTok{ cholesky}
\ImportTok{from}\NormalTok{ time }\ImportTok{import}\NormalTok{ time}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}                                  \CommentTok{\# example problem size}
\NormalTok{A\_n }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{*}\NormalTok{np.diag(np.ones(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{), }\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+} \OperatorTok{\textbackslash{}}  \CommentTok{\# a tridiagonal band matrix}
    \DecValTok{2}\OperatorTok{*}\NormalTok{np.diag(np.ones(n), }\DecValTok{0}\NormalTok{) }\OperatorTok{+} \OperatorTok{\textbackslash{}}
    \OperatorTok{{-}}\DecValTok{1}\OperatorTok{*}\NormalTok{np.diag(np.ones(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{), }\DecValTok{1}\NormalTok{)}
\NormalTok{tic }\OperatorTok{=}\NormalTok{ time()                            }\CommentTok{\# start the timer}
\NormalTok{\_ }\OperatorTok{=}\NormalTok{ cholesky(A\_n)                       }\CommentTok{\# perform the computation}
\NormalTok{toc }\OperatorTok{=}\NormalTok{ time()                            }\CommentTok{\# stop the timer}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}n: }\SpecialCharTok{\{n\}}\SpecialStringTok{ {-}{-} t\_n: }\SpecialCharTok{\{}\NormalTok{toc}\OperatorTok{{-}}\NormalTok{tic}\SpecialCharTok{:.4e\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\emph{Hinweis: Hier geht es um die Methodik und um eine sinnvolle Interpretation der Ergebnisse. Es kann gut sein, dass die Ergebnisse auf verschiedenen Rechnern verschieden ausfallen. Außerdem können für große \(n\) (wenn der Exponent und die Konstante am besten sichtbar sind) auf einmal bspw. ein zu voller Arbeitsspeicher die Berechnung negativ beeinflussen.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Diskutieren Sie, wie Laufzeitmessungen (bspw. zur Komplexitätsanalyse eines Verfahrens) aufgesetzt werden sollten, um reproduzierbare Ergebnisse zu erhalten. Was sollte dokumentiert werden, damit dritte Personen die Ergebnisse einordnen und ggf. reproduzieren können.
\end{enumerate}

Weiterführende Literatur:

\begin{itemize}
\tightlist
\item
  \href{https://de.wikipedia.org/wiki/Algorithmus\#Definition}{wikipedia:Algorithmus}
\end{itemize}

\hypertarget{fehler-und-konditionierung}{%
\chapter{Fehler und Konditionierung}\label{fehler-und-konditionierung}}

\def\kij{(\kappa_{A,x})_{ij}}

Berechnungen auf einem Computer verursachen unvermeidlich Fehler, und die Effizienz oder Leistung von Algorithmen ist immer das Verhältnis von Kosten zu Genauigkeit.

Zum Beispiel:

\begin{itemize}
\item
  Allein aus der Betrachtung von Rundungsfehlern kann die Genauigkeit einfach und signifikant verbessert werden, indem auf \emph{Langzahlarithmetik} zurückgegriffen wird, was jedoch höhere Speicheranforderungen und eine höhere Rechenlast mit sich bringt.
\item
  In iterativen Verfahren können Speicher und Rechenaufwand leicht eingespart werden, indem die Iteration in einem frühen Stadium gestoppt wird - natürlich auf Kosten einer weniger genauen Lösungsapproximation.
\end{itemize}

\leavevmode\hypertarget{rem-accu-iter}{}%
\begin{JHSAYS}
Beide, irgendwie trivialen Beobachtungen sind grundlegende Bestandteile des Trainings neuronaler Netzwerke. Erstens wurde beobachtet, dass Zahldarstellungen mit \emph{einfacher Genauigkeit} (im Vergleich zum gängigen \emph{double precision}) Rechenkosten sparen kann, mit nur geringen Auswirkungen auf die Genauigkeit. Zweitens ist das Training ein iterativer Prozess mit oft langsamer Konvergenz, sodass der richtige Zeitpunkt für einen vorzeitigen Abbruch des Trainings entscheidend ist.

\end{JHSAYS}

\hypertarget{fehler}{%
\section{Fehler}\label{fehler}}

\begin{definition}[Absolute und relative Fehler]
\protect\hypertarget{def:errors}{}\label{def:errors}Sei \(x\in\mathbb R^{}\) die interessierende Größe und \(\tilde x \in \mathbb R^{}\) eine Annäherung daran. Dann wird der \emph{absolute Fehler} definiert als
\begin{equation*}
|\delta x|:=|\tilde x- x|
\end{equation*}
und der \emph{relative Fehler} als
\begin{equation*}
\frac{|\delta x|}{|x|}=\frac{|\tilde x- x|}{|x|}.
\end{equation*}
\end{definition}

\leavevmode\hypertarget{rem-rel-abs-err}{}%
\begin{JHSAYS}
Generell wird der relative Fehler bevorzugt, da er den gemessenen Fehler in den richtigen Bezug setzt. Zum Beispiel kann ein absoluter Fehler von \(10\) km/h je nach Kontext groß oder klein sein.

\end{JHSAYS}

\hypertarget{kondition}{%
\section{Kondition}\label{kondition}}

Als Nächstes definieren wir die \emph{Kondition} eines Problems \(A\) und analog eines Algorithmus (der das Problem löst). Dafür lassen wir \(x\) einen Parameter/Eingabe des Problems sein und \(y=A(x)\) die entsprechende Lösung/Ausgabe. Die Kondition ist ein Maß dafür, inwieweit eine Änderung \(x+\delta x\) in der Eingabe die resultierende relative Änderung in der Ausgabe beeinflusst. Dafür betrachten wir
\begin{equation*}
\delta y = \tilde y - y = A(\tilde x) - A(x) = A(x+\delta x) - A(x)
\end{equation*}
welches nach Division durch \(y=A(x)\) und Erweiterung durch \(x\,\delta x\) wird zu
\begin{equation*}
\frac{\delta y}{y} = \frac{A(x+\delta x)-A(x)}{\delta x}\frac{x}{A(x)}\frac{\delta x}{x}.
\end{equation*}
Für infinitesimal kleine \(\delta x\) wird der Differenzenquotient \(\frac{A(x+\delta x)-A(x)}{\delta x}\) zur Ableitung \(\frac{\partial A}{\partial x}(x)\), so dass wir die Kondition des Problems/Algorithmus bei \(x\) abschätzen können durch

\begin{equation}
\frac{|\delta y|}{|y|} \approx |\frac{\partial A}{\partial x}(x)|\frac{|x|}{|A(x)|}\frac{|\delta x|}{|x|}=:\kappa_{A,x}\frac{|\delta x|}{|x|}.
\label{eq:eqn-scalar-cond}
\end{equation}

Wir nennen \(\kappa_{A,x}\) die Konditionszahl.

Für vektorwertige Probleme/Algorithmen können wir die Konditionszahl darüber definieren, wie eine Differenz in der \(j\)-ten Eingabekomponente \(x_j\) die \(i\)-te Komponente \(y_i=A_i(x)\) der Ausgabe beeinflusst.

\begin{definition}[Konditionszahl]
\protect\hypertarget{def:condition}{}\label{def:condition}Für ein Problem/Algorithmus \(A\colon \mathbb R^{n}\to \mathbb R^{m}\) nennen wir
\begin{equation*}
(\kappa_{A,x})_{ij} := \frac{\partial A_i}{\partial x_j}(x) \frac{x_j}{A_i(x)}
\end{equation*}
die partielle \emph{Konditionszahl} des Problems. Ein Problem wird als \emph{gut konditioniert} bezeichnet, wenn \(|(\kappa_{A,x})_{ij}|\approx 1\) und als \emph{schlecht konditioniert}, wenn \(|(\kappa_{A,x})_{ij}\gg 1|\), für alle \(i=1,\dotsc,m\) und \(j=1,\dotsc,m\).
\end{definition}

\leavevmode\hypertarget{rem-vector-valued-cond}{}%
\begin{JHSAYS}
Anstatt die skalaren Komponentenfunktionen von \(A\colon \mathbb R^{n} \to \mathbb R^{m}\) zu verwenden, kann man die Berechnungen, die zu \eqref{eq:eqn-scalar-cond} geführt haben, mit vektorwertigen Größen in den entsprechenden Normen wiederholen.

\end{JHSAYS}

\hypertarget{kondition-der-grundrechenarten}{%
\section{Kondition der Grundrechenarten}\label{kondition-der-grundrechenarten}}

Da einfach jede Operation von Zahlen auf dem Computer auf die Grundrechenarten zurückgeht, ist es wichtig sich zu vergegenwärtigen wie sich diese Basisoperationen in Bezug auf kleine Fehler verhalten.

\hypertarget{addition}{%
\subsection{Addition}\label{addition}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ A(x, y):}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{+}\NormalTok{y}

\NormalTok{x, tx, y }\OperatorTok{=} \FloatTok{1.02}\NormalTok{, }\FloatTok{1.021}\NormalTok{, }\OperatorTok{{-}}\FloatTok{1.00}
\NormalTok{z }\OperatorTok{=}\NormalTok{ A(x, y)}
\NormalTok{tz }\OperatorTok{=}\NormalTok{ A(tx, y)}
\NormalTok{relerrx }\OperatorTok{=}\NormalTok{ (tx }\OperatorTok{{-}}\NormalTok{ x)}\OperatorTok{/}\NormalTok{x        }\CommentTok{\# here: 0.00098039}
\NormalTok{relerrz }\OperatorTok{=}\NormalTok{ (tz }\OperatorTok{{-}}\NormalTok{ z)}\OperatorTok{/}\NormalTok{z        }\CommentTok{\# here: 0.04999999}
\NormalTok{kondAx }\OperatorTok{=}\NormalTok{ relerrz}\OperatorTok{/}\NormalTok{relerrx    }\CommentTok{\# here: 50.9999999}
\end{Highlighting}
\end{Shaded}

In diesem Code Beispiel liegt der relative Fehler in \(x\) bei etwa \(0.01\)\% und im Ausgang \(z\) bei etwa \(5\)\%, was einer etwa \(50\)-fachen Verstärkung entspricht.
Für die Konditionszahl der Addition \(A_y\colon x \to y+x\) gilt:
\begin{equation*}
\kappa_{A_y;x} = \frac{|x|}{|x+y|} = \frac{1}{|1+\frac{y}{x}|}.
\end{equation*}

Diese Konditionszahl kann offenbar beliebig groß werden, wenn \(x\) nah an \(-y\) liegt. Jan spricht von Auslöschung und tatsächlich lässt sich nachvollziehen, dass in diesem Fall die vorderen (korrekten) Stellen einer Zahl von einander abgezogen werden und die hinteren (möglicherweise inkorrekten) Stellen übrig bleiben.

\leavevmode\hypertarget{rem-accu-iter}{}%
\begin{JHSAYS}
Praktisch gesagt: Hantiert Jan mit Addition großer Zahlen um ein kleines Ergebnis erzielen ist das numerisch sehr ungünstig.

\end{JHSAYS}

\hypertarget{multiplikation}{%
\subsection{Multiplikation}\label{multiplikation}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ M(x, y):}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{*}\NormalTok{y}

\NormalTok{x, tx, y }\OperatorTok{=} \FloatTok{1.02}\NormalTok{, }\FloatTok{1.021}\NormalTok{, }\OperatorTok{{-}}\FloatTok{1.00}
\NormalTok{z }\OperatorTok{=}\NormalTok{ M(x, y)}
\NormalTok{tz }\OperatorTok{=}\NormalTok{ M(tx, y)}
\NormalTok{relerrx }\OperatorTok{=}\NormalTok{ (tx }\OperatorTok{{-}}\NormalTok{ x)}\OperatorTok{/}\NormalTok{x        }\CommentTok{\# here: 0.00098039}
\NormalTok{relerrz }\OperatorTok{=}\NormalTok{ (tz }\OperatorTok{{-}}\NormalTok{ z)}\OperatorTok{/}\NormalTok{z        }\CommentTok{\# here: 0.00098039}
\NormalTok{kondMx }\OperatorTok{=}\NormalTok{ relerrz}\OperatorTok{/}\NormalTok{relerrx    }\CommentTok{\# here: 1.0}
\end{Highlighting}
\end{Shaded}

Das Ergebnis \texttt{1.0} für die empirisch ermittelte Konditionszahl war kein Zufall. Es gilt im Allgemeinen für \(M_y \colon x \to yx\) dass
\begin{equation*}
\kappa_{M_y;x} = |y|\frac{|x|}{|xy|} = 1.
\end{equation*}
Die Multiplikation ist also generell gut konditioniert.

\hypertarget{wurzelziehen}{%
\subsection{Wurzelziehen}\label{wurzelziehen}}

Das Berechnen der Quadratwurzel \(W\colon x \to \sqrt x\) hat die Konditionszahl \(\frac 12\). Bei Konditionszahlen kleiner als \(1\) verringert sich der relative Fehler, Jan spricht von \emph{Fehlerdämpfung}.

\hypertarget{uxfcbungen-1}{%
\section{Übungen}\label{uxfcbungen-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Leiten Sie die \emph{Konditionszahl} wie in \eqref{eq:eqn-scalar-cond} für eine vektorwertige Funktion \(A\colon \mathbb R^{n} \to \mathbb R^{m}\) her. Wo spielt eine Matrixnorm eine Rolle?
\item
  Leiten Sie mit dem selben Verfahren die Konditionszahl einer invertierbaren Matrix \(M\) her, d.h. die Kondition des Problems \(x\to y = M^{-1}x\). Wo spielt die Matrixnorm eine Rolle?
\item
  Leiten Sie die Konditionszahlen für die Operationen \emph{Division} und \emph{Quadratwurzelziehen} her.
\item
  Veranschaulichen Sie an der Darstellung des Vektors \(P=[1, 1]\) in der Standardbasis \(\{[1, 0], \,[0, 1]\}\) und in der Basis \(\{[1, 0], \,[1, 0.1]\}\) unter Verweis auf die Kondition der Addition, warum \emph{orthogonale Basen} als \emph{gut konditioniert} gelten.
\end{enumerate}

\hypertarget{iterative-methoden}{%
\chapter{Iterative Methoden}\label{iterative-methoden}}

Allgemein nennen wir ein Verfahren, das sukzessive (also \emph{iterativ}) eine Lösung \(z\) über eine iterativ definierte Folge \(x_{k+1}=\phi_k(x_k)\) annähert ein \emph{iteratives Verfahren}.

Hierbei können \(z\), \(x_k\), \(x_{k+1}\) skalare, Vektoren oder auch unendlich dimensionale Objekte sein und \(\phi_k\) ist die Verfahrensfunktion, die das Verfahren beschreibt.
Oftmals ist das Verfahren immer das gleiche egal bei welchem Schritt \(k\) Jan gerade ist, weshalb auch oft einfach \(\phi\) geschrieben wird.

Bekannte Beispiele sind iterative Verfahren zur

\begin{itemize}
\tightlist
\item
  Lösung linearer Gleichungssysteme (z.B. \emph{Gauss-Seidel})
\item
  Lösung nichtlinearer Gleichungssysteme (z.B. \emph{Newton})
\item
  Optimierung (z.B. von ML Modellen mittels \emph{Gradientenabstieg})
\end{itemize}

Der Einfachheit halber betrachten wir zunächst \(z\), \(x_k\), \(x_{k+1}\in \mathbb R^{}\).
Die Erweiterung der Definitionen erfolgt dann über die Formulierung mit Hilfe passender Normen anstelle des Betrags.

\begin{definition}[Konvergenz einer Iteration]
\protect\hypertarget{def:iterative-convergence}{}\label{def:iterative-convergence}Eine Iteration die eine Folge \((x_k)_{k\in \mathbb N^{}}\subset \mathbb R^{}\) produziert, heißt \emph{konvergent der Ordnung \(p\)} (gegen \(z\in \mathbb R^{}\)) mit \(p\geq 1\), falls eine Konstante \(c>0\) existiert sodass
\begin{equation}
|x_{k+1} - z| \leq c|x_k-z|^p,
\label{eq:eqn-iterative-cnvrgnc}
\end{equation}
für \(k=1, 2, \dotsc\).

Ist \(p=1\), so ist \(0<c<1\) notwendig für Konvergenz, genannt \emph{lineare Konvergenz} und das kleinste \(c\), das \eqref{eq:eqn-iterative-cnvrgnc} erfüllt, heißt \emph{(lineare) Konvergenzrate}.

Gilt \(p=1\) und gilt \(|x_{k+1} - z| \leq c_k|x_k-z|^p\) mit \(c_k \to 0\) für \(k\to \infty\) heißt die Konvergenz \emph{superlinear}.
\end{definition}

\leavevmode\hypertarget{rem-conv-iterat}{}%
\begin{JHSAYS}
Wiederum gelten Konvergenzaussagen eigentlich für die Kombination aus Methode und Problem. Dennoch ist es allgemeine Praxis, beispielsweise zu sagen, dass das \emph{Newton-Verfahren quadratisch konvergiert}.

\end{JHSAYS}

Wir stellen fest, dass im Limit (und wenn vor allem \(\phi_k \equiv \phi\) ist) gelten muss, dass
\begin{equation*}
x=\phi(x),
\end{equation*}
die Lösung (bzw. das was berechnet wurde) ein \emph{Fixpunkt} der Verfahrensfunktion ist.

In der Tat lassen sich viele iterative Methoden als Fixpunktiteration formulieren und mittels Fixpunktsätzen analysieren. Im ersten Teil dieses Kapitels, werden wir Fixpunktmethoden betrachten.

Als eine Verallgemeinerung, z.B. für den Fall dass \(\phi\) tatsächlich von \(k\) abhängen soll oder dass kein Fixpunkt sondern beispielsweise ein Minimum angenähert werden soll, werden wir außerdem sogenannte \emph{Auxiliary Function Methods} einführen und anschauen.

\hypertarget{iterative-methoden-als-fixpunktiteration}{%
\section{Iterative Methoden als Fixpunktiteration}\label{iterative-methoden-als-fixpunktiteration}}

Um eine iterative Vorschrift, beschrieben durch \(\phi\), als (konvergente) Fixpunktiteration zu charakterisieren, sind zwei wesentliche Bedingungen nachzuweisen

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  die gesuchte Lösung \(z\) ist ein Fixpunkt des Verfahrens, also \(\phi(z)=z\).
\item
  Für einen Startwert \(x_0\), konvergiert die Folge \(x_{k+1}:=\phi(x_k)\), \(k=1,2,\dotsc\), gegen \(z\).
\end{enumerate}

Dazu kommen Betrachtungen von Konditionierung, Stabilität und Konvergenzordnung.

Wir beginnen mit etwas analytischer Betrachtung. Sei \(g \colon \mathbb R^{}\to \mathbb R^{}\) stetig differenzierbar und sei \(z\in \mathbb R^{}\) ein Fixpunkt von \(g\). Dann gilt, dass
\begin{equation*}
\lim_{x\to z} \frac{g(x)-g(z)}{x-z} = \lim_{x\to z} \frac{g(x)-z}{x-z} = g'(z)
\end{equation*}
und damit, dass für ein \(x_k\) in einer Umgebung \(U\) um \(z\) gilt, dass
\begin{equation*}
|g(x_k)-z|\leq c |x_k-z|
\end{equation*}
mit \(c=\sup_{x\in U}|g'(x)|\).
Daraus können wir direkt ableiten, dass

\begin{itemize}
\tightlist
\item
  wenn \(|g'(z)|<1\) ist, dann ist die Vorschrift \(x_{k+1}=\phi(x_k):=g(x_k)\) \emph{lokal} linear konvergent
\item
  wenn \(g'(z)=0\) dann sogar \emph{superlinear}
\item
  wenn \(|g'(z)|>1\) ist, dann divergiert die Folge weg von \(z\) (und der Fixpunkt wird \emph{abstoßend} genannt).
\end{itemize}

Für höhere Konvergenzordnungen wird diese Beobachtung im folgenden Satz verallgemeinert.

\begin{theorem}[Konvergenz höherer Ordnung bei glatter Fixpunktiteration]
\protect\hypertarget{thm:thm-smooth-fp-conv}{}\label{thm:thm-smooth-fp-conv}Sei \(g\colon D\subset \mathbb R^{}\to \mathbb R^{}\) \(p\)-mal stetig differenzierbar, sei \(z\in D\) ein Fixpunkt von \(g\). Dann konvergiert die Fixpunktiteration \(x_{k+1}=g(x_k)\) \emph{lokal} mit Ordnung \(p\), genau dann wenn
\begin{equation*}
g'(z)=\dotsm g^{(p-1)}(z)=0, \quad g^{(p)}\neq 0.
\end{equation*}
\end{theorem}

\begin{proof}
Siehe (Richter and Wick \protect\hyperlink{ref-RicW17}{2017}, Thm. 6.31)
\end{proof}

\leavevmode\hypertarget{rem-smooth-fp-conv}{}%
\begin{JHSAYS}
Das \emph{genau dann wenn} in Satz \ref{thm:thm-smooth-fp-conv} ist so zu verstehen, dass die Konvergenzordnung genau gleich \(p\) ist, was insbesondere beinhaltet, dass wenn \(g^{(p)}=0\) ist, die Ordnung eventuell grösser als \(p\) ist. (Jan ist verleitet zu denken, dass in diesem Fall die Iteration nicht (oder mit einer niedrigeren Ordnung) konvergieren würde).

\end{JHSAYS}

Ist die Iterationsvorschrift linear (wie bei der iterativen Lösung linearer Gleichungssysteme), so ist die erste Ableitung \(\phi'\) konstant (und gleich der Vorschrift selbst) und alle weiteren Ableitungen sind \(0\). Dementsprechend, können wir

\begin{itemize}
\tightlist
\item
  maximal lineare Konvergenz erwarten
\item
  (die aber beispielsweise durch dynamische Anpassung von Parametern auf superlinear verbessert werden kann)
\item
  dafür aber vergleichsweise direkte Verallgemeinerungen zu mehrdimensionalen und sogar \(\infty\)-dimensionalen Problemstellungen.
\end{itemize}

Zur Illustration betrachten wir den \emph{Landweber-Algorithmus} zur näherungsweisen Lösung von ``\(Ax=b\)''.
Dieser Algorithmus wird zwar insbesondere nicht verwendet um ein lineares Gleichungssystem zu lösen, durch die Formulierung für möglicherweise überbestimmte Systeme und die Verbindung zur iterativen Optimierung hat er aber praktische Anwendungen in \emph{compressed sensing} und auch beim \emph{supervised learning} gefunden; vgl. \href{https://en.wikipedia.org/wiki/Landweber_iteration}{wikipedia:Landweber\_iteration}.

\begin{definition}[Landweber Iteration]
\protect\hypertarget{def:def-landweber-alg}{}\label{def:def-landweber-alg}Sei \(A\in \mathbb R^{m\times n}\) und \(b\in \mathbb R^{m}\). Dann ist, ausgehend von einem Startwert \(x_0 \in \mathbb R^{n}\), die \emph{Landweber Iteration} definiert über
\begin{equation*}
x_{k+1} = x_k - \gamma A^T(Ax_k -b ),
\end{equation*}
wobei der Parameter \(\gamma\) als \(0<\gamma< \frac{2}{\|A\|_2}\) gewählt wird.
\end{definition}

Zur Illustration der Argumente, die die Konvergenz einer Fixpunktiteration mit linearer Verfahrensfunktion herleiten, zeigen wir die Konvergenz im Spezialfall, dass \(Ax=b\) ein reguläres lineares Gleichungssystem ist.

\begin{theorem}[Konvergenz der Landweber Iteration]
\protect\hypertarget{thm:thm-lw-conv}{}\label{thm:thm-lw-conv}Unter den Voraussetzungen von Definition \ref{def:def-landweber-alg} und für \(m=n\) und \(A\in \mathbb R^{n\times n}\) regulär, konvergiert die Landweber Iteration linear für einen beliebigen Startwert \(x_0\).
\end{theorem}

\begin{proof}
Ist das Gleichungssystem \(Az=b\) eindeutig lösbar, bekommen wir direkt, dass
\begin{equation*}
\begin{split}
x_{k+1} - z &= x_k - \gamma A^T(Ax_k -b ) - z  \\
&= x_k - \gamma A^TAx_k -\gamma A^Tb - z \\
&= (I-\gamma A^TA)x_k -\gamma A^TAz - z \\
&= (I-\gamma A^TA)(x_k - z)
\end{split}
\end{equation*}
Damit ergibt eine Abschätzung in der \(2\)-Norm und der induzierten Matrixnorm, dass
\begin{equation*}
\|x_{k+1}-z\|_2 \leq \|I-\gamma A^TA\|_2\|x_k-z\|_2
\end{equation*}
gilt, was lineare Konvergenz mit der Rate \(c=\|I-\gamma A^TA\|_2\) bedeutet, wobei \(c<1\) gilt nach der getroffenen Voraussetzung, dass \(0<\gamma<\frac{2}{\|A^TA\|_2}\) ist.
\end{proof}

\leavevmode\hypertarget{rem-fpconv-iteration-contraction}{}%
\begin{JHSAYS}
Das Prinzip dieser Beweise ist festzustellen, dass die Verfahrensfunktion in der Nähe des Fixpunkts eine \emph{Kontraktion} ist, d.h. Lipschitz-stetig mit Konstante \(L<1\).

\end{JHSAYS}

\hypertarget{gradientenabstiegsverfahren}{%
\section{Gradientenabstiegsverfahren}\label{gradientenabstiegsverfahren}}

Anstelle der Nullstellensuche behandeln wir jetzt die Aufgabe
\begin{equation*}
f(x) \to \min_{x\in \mathbb R^{n}}
\end{equation*}
für eine Funktion \(f \colon \mathbb R^{n} \to \mathbb R^{}\), also die Aufgabe ein \(z^*\in \mathbb R^{n}\) zu finden, für welches der Wert von \(f\) minimal wird.

Ist \(f\) differenzierbar (der Einfachheit halber nehmen wir an, dass \emph{totale} Differenzierbarkeit vorliegt; es würde aber Differenzierbarkeit in einer beliebigen Richtung, also \emph{Gateaux}-Differenzierbarkeit, genügen), so gilt, dass in einem Punkt \(x_0\), der Gradient \(\nabla f(x_0)\) (ein Vektor im \(\mathbb R^{n}\)) in die Richtung des stärksten Wachstums zeigt und der negative Gradient \(-\nabla f(x_0)\) in die Richtung, in der \(f\) kleiner wird.

Auf der Suche nach einem Minimum könnten wir also ausnutzen, dass
\begin{equation*}
f(x_0 - \gamma_0 \nabla f(x_0)):=f(x_1)   < f(x_0)
\end{equation*}
falls \(\gamma_0\) nur genügend klein ist und \(\nabla f(x_0) \neq 0\).

\leavevmode\hypertarget{rem-gamma-zerograd}{}%
\begin{JHSAYS}
Was ist, wenn \(\nabla f(x_0) = 0\) ist und warum gibt es andernfalls so ein \(\gamma_0\) und wie könnten wir es systematisch bestimmen?

\end{JHSAYS}

Diese Beobachtung am nächsten Punkt \(x_1\) wiederholt, führt auf des \emph{Gradientenabstiegsverfahren}.

\begin{definition}[Gradientenabstiegsverfahren]
\protect\hypertarget{def:def-grad-descent}{}\label{def:def-grad-descent}Sei \(f\colon \mathbb R^{n} \to \mathbb R^{}\) differenzierbar, dann heißt die Iteration
\begin{equation}
x_{k+1} := x_k - \gamma_k\nabla f(x_k)
\label{eq:eqn-grad-desc}
\end{equation}
für passend gewählte \(\gamma_k>0\), das
Gradientenabstiegsverfahren zur Berechnung eines Minimums von \(f\).
\end{definition}

\begin{lemma}[Gradientenabstieg als konvergente Fixpunkt Iteration]
\protect\hypertarget{lem:lem-graddesc-as-fp}{}\label{lem:lem-graddesc-as-fp}Sei \(D\subset \mathbb R^{n}\) offen und der Definitionsbereich von \(f\). Ist \(x^*\in D\) ein Minimum von \(f\) und ist \(\nabla f\colon D \to \mathbb R^{n}\) \emph{Lipschitz-stetig} mit Konstante \(L\), dann definiert \eqref{eq:eqn-grad-desc} mit \(\gamma_k \equiv \frac L2\) eine konvergente Fixpunktiteration für \(\phi(x) = x-\gamma \nabla f(x)\) mit einem lokalen Minimum \(z^*\) von \(f\) als Fixpunkt.
\end{lemma}

\begin{proof}
Einigermaßen direkt nachzuweisen.
\end{proof}

Die vorhergegangenen Überlegungen gingen von \(z^*\) innerhalb eines offenen Definitionsbereichs \(D\) von \(f\) aus, wo ein Minimum durch \(\nabla f(x^*)=0\) und \(f(x^*)\leq f(x)\) für alle \(x\) aus einer Umgebung von \(x^*\) gegeben ist.

Ein typischer Anwendungsfall ist jedoch, dass \(x^*\) in einem zulässigen Bereich \(C\) liegen muss, der eine echte Teilmenge von \(D\) ist.
Dann besteht die Möglichkeit, dass ein (lokales) Minimum am Rand des Bereichs \(C\) vorliegt (wo die Funktion \(f\) zwar weiter fällt, aber ``das Ende'' der Zulässigkeit erreicht ist).

Ist \(C\subset \mathbb R^{n}\) konvex und abgeschlossen, so gilt folgendes allgemeine Resultat (dessen Argumente und Voraussetzungen auch leicht auf beispielsweise Funktionen auf allgemeinen Hilberträumen oder Mengen die nur lokal konvex sind angepasst werden können).

\begin{theorem}[Projiziertes Gradientenabstiegsverfahren]
\protect\hypertarget{thm:thm-prj-grad-desc}{}\label{thm:thm-prj-grad-desc}Sei \(C \subset \mathbb R^{n}\) konvex und abgeschlossen, dann ist die Projektion \(P_C\colon \mathbb R^{n} \to C\) mittels
\begin{equation*}
P_C(x) := x^*,
\end{equation*}
wobei \(x^*\) das Minimierungsproblem
\begin{equation*}
\min_{z\in C} \|x-z\|_2
\end{equation*}
löst, wohldefiniert.

Sei ferner \(f\colon D \to \mathbb R^{}\), mit \(C \subset D\), differenzierbar mit Lipschitz-stetigem Gradienten mit Konstante \(L\), dann konvergiert das projizierte Gradientenabstiegsverfahren
\begin{equation}
x_{k+1} := P_C(x_k - \gamma_k\nabla f(x_k))
\label{eq:eqn-prj-grad-desc}
\end{equation}
für jeden Anfangswert \(x_0\in D\) und beliebige Wahl von \(\gamma_k < \frac L2\) zu einem lokalen Minimum \(z^*\in C\) von \(f\).
\end{theorem}

\begin{proof}
Siehe Vorlesung.
\end{proof}

\hypertarget{auxiliary-function-methods}{%
\section{Auxiliary Function Methods}\label{auxiliary-function-methods}}

In manchen Fällen ist es hilfreich, wenn das Problem selbst iterativ definiert wird.
Dann wird in jedem Schritt ein vereinfachtes Problem gelöst und mit der gewonnenen Information, kann das Problem dem eigentlichen aber schwierigen Originalproblem näher gebracht werden.

Als Beispiel betrachten wir das Problem
\begin{equation}
f(x)=x_1^2+x_2^2 \to \min_{x\in D\subset \mathbb R^{2}}, \quad \text{wobei }D:=\{x\in \mathbb R^{2}\,|\, x_1+x_2 \geq 0\}.
\label{eq:eqn-exa-cnstrnt-optiprob}
\end{equation}

Zwar ist hier das projizierte Gradientenabstiegsverfahren unmittelbar anwendbar, wir werden aber sehen, dass wir mit einer Hilfsfunktion, sogar die analytische Lösung direkt ablesen können.

Für \(k=1,2,\dotsc\), sei das Hilfsproblem definiert als
\begin{equation}
B_k(x):=x_1^2+x_2^2 - \frac{1}{k}\log(x_1+x_2-1)\to \inf_C,
\label{eq:eqn-exa-relaxed-optiprob}
\end{equation}
wobei \(C=\{x\,|\,x_1+x_2>0\}\). Aus dem ``0-setzen'' der partiellen Ableitungen von \(B_k\), bekommen wir
\begin{equation*}
x_{k,1}=x_{k,2} = \frac 14 + \sqrt{\frac 14 + \frac 1k},
\end{equation*}
also eine Folge, die zum Minimum des eigentlichen Problems konvergiert.

Zur Analyse solcher Verfahren, allgemein geschrieben als
\begin{equation}
G_k(x) = f(x) + g_k(x) \to \min_C, \quad k=1,2,\dotsc
\label{eq:eqn-gen-af-method}
\end{equation}
werden die folgenden zwei Bedingungen gerne herangenommen:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Die Iteration \eqref{eq:eqn-gen-af-method} heißt \emph{auxiliary function} (AF) Methode, falls \(g_k(x)\geq 0\), für alle \(k\in \mathbb N\) und \(x\in C\), \(g_k(x_{k-1})=0\).
\item
  Die Iteration gehört zur \emph{SUMMA} Klasse, falls \(G_k(x)-G_k(x_k) \geq g_{k+1}(x)\).
\end{enumerate}

Unter der 1. Annahme gilt sofort, dass
\begin{equation*}
f(x_{k}) \leq f(x_{k}) + g_k(x_k) = G_k(x_k) \leq G_k(x_{k-1}) = f(x_{k-1}) + g_k(x_{k-1}) = f(x_{k-1}),
\end{equation*}
also dass die Folge \(\{f(x_k)\}_{k\in \mathbb N}\) monoton fallend ist.

Aus der 2. Annahme folgt dann, dass \(f(x_k) \to \beta^*=\inf{x\in c}f(x)\), für \(k\to \infty\), was sich wie folgt argumentieren läßt:

Angenommen, \(f(x_k) \to \beta > \beta^*\), dann existiert ein \(z\in C\), sodass \(\beta > f(z) \geq \beta^*\). Dann ist, der 2. 2. Annahme nach,
\begin{equation*}
\begin{split}
g_k(z) - g_{k+1}(z) &= g_k(z) - (G_k(z)-G_k(x_k))    \\
&=g_k(z) - (f(z) + g_k(z) - f(x_k) - g_k(x_k)) \\
&\quad \geq f(z) - \beta + g_k(x_k) \geq f(z) - \beta > 0,
\end{split}
\end{equation*}
was impliziert, dass \(0\leq g_{k+1}(z)<g_k(z)+c\), für alle \(k\) und eine konstantes \(c>0\), was ein Widerspruch ist.

Wir rechnen nach, dass \eqref{eq:eqn-exa-relaxed-optiprob} die Annahmen 1. und 2. erfüllt (allerdings erst nach einigen äquivalenten Umformungen).

Zunächst halten wir fest, dass die Iteration in \eqref{eq:eqn-exa-relaxed-optiprob} geschrieben werden kann als
\begin{equation}
B_k(x) = f(x) + \frac 1k b(x) \to \min
\label{eq:eqn-min-barrier}
\end{equation}
was, da eine Skalierung das Minimum nicht änder ebensowenig wie die Addition eines konstanten Termes (konstant bezüglich \(x\)),
äquivalent ist zu
\begin{equation*}
G_k(x) = f(x) + g_k(x)
\end{equation*}
mit
\begin{equation*}
g_k(x) = [(k-1)f(x) + b(x)] - [(k-1)f(x_{k-1}) + b(x_{k-1})].
\end{equation*}.

Wir rechnen direkt nach, dass \(g_k(x)\geq 0\) ist (folgt daraus, dass \(x_{k-1}\) optimal für \(G_{k-1}\) ist), dass \(g_k(x_{k-1})=0\) ist, und dass \(G_k(x)-G_k(x_k)=g_{k+1}(x)\) ist (dafür muss ein bisschen umgeformt werden), sodass die Voraussetzungen für AF und SUMMA erfüllt sind.

Zum Abschluss einige Bemerkungen

\begin{itemize}
\tightlist
\item
  das allgemeine \(b\) in \eqref{eq:eqn-min-barrier} und im speziellen in \eqref{eq:eqn-exa-relaxed-optiprob} ist eine sogenannte \emph{barrier} Funktion, die beispielsweise einen zulässigen Bereich als \(C=\{x\,|\, b(x)< \infty\}\) definiert.
\item
  weitere Methoden der Optimierung, die in die betrachteten (AF) Klassen fallen sind beispielsweise \emph{Majorization Minimization}, \emph{Expectation Maximization}, \emph{Proximal Minimization} oder \emph{Regularized Gradient Descent}.
\item
  Eine schöne Einführung und Übersicht liefert das Skript \emph{Lecture Notes on Iterative Optimization Algorithms} (Byrne \protect\hyperlink{ref-Byr14}{2014}).
\end{itemize}

\hypertarget{stochastisches-gradientenabstiegsverfahren}{%
\section{Stochastisches Gradientenabstiegsverfahren}\label{stochastisches-gradientenabstiegsverfahren}}

\hypertarget{uxfcbungen-2}{%
\section{Übungen}\label{uxfcbungen-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bestimmen Sie die Konvergenzordnung und die Rate für das Intervallschachtelungsverfahren zur Nullstellenberechnung.
\item
  Benutzen Sie Satz \ref{thm:thm-smooth-fp-conv} um zu zeigen, dass aus \(f\) zweimal stetig differenzierbar und \(f(z)=0\), \(f'(z)\neq 0\) für ein \(z\in D(f)\) folgt, dass das Newton-Verfahren zur Berechnung von \(z\) lokal quadratisch konvergiert. \emph{Hinweis}: Hier ist es wichtig zunächst zu verstehen, was die Funktion \(f\) ist und was die Verfahrensfunktion \(\phi\) ist.
\item
  Bestimmen sie die Funktion \(h\) in \(\phi(x) = x+h(x)f(x)\) derart, dass unter den Bedingungen von 2. die Vorschrift \(\phi\) einen Fixpunkt in \(z\) hat und derart, dass die Iteration quadratisch konvergiert.
\item
  Erklären Sie an Hand von Satz \ref{thm:thm-smooth-fp-conv} (und den vorhergegangenen Überlegungen) warum Newton für das Problem \emph{finde \(x\), so dass \(x^2=0\) ist} \textbf{nicht} quadratisch (aber doch superlinear) konvergiert.
\item
  Beweisen Sie, dass für \(0<\gamma< \frac{2}{\|A^TA\|_2}\) gilt, dass\(\|I-\gamma A^TA\|_2<1\) für beliebige \(A\in \mathbb R^{m \times n}\).
\item
  Rechnen Sie nach, dass die Landweber Iteration aus Definition \ref{def:def-landweber-alg} einem gedämpften Gradientenabstiegsverfahren für \(\|Ax-b\|_2^2 \to \min_{x\in \mathbb R^{m}}\) entspricht.
\item
  Implementieren Sie das projizierte Gradientenabstiegsverfahren für \eqref{eq:eqn-exa-cnstrnt-optiprob} und das \emph{nichtprojizierte} aber an \(k\) angepasste Gradientenabstiegsverfahren für \eqref{eq:eqn-exa-relaxed-optiprob}. Vergleichen Sie die Konvergenz für verschiedene Startwerte.
\end{enumerate}

\hypertarget{nachklapp}{%
\chapter{Nachklapp}\label{nachklapp}}

Ein paar lose Beispiele wo Numerik und maschinelles Lernen sich treffen.

\begin{itemize}
\item
  Iterative Methoden

  \begin{itemize}
  \tightlist
  \item
    Konvergenz/Konvergenzraten
  \item
    stochastische Konvergenz
  \item
    lokale Extrema
  \item
    randomisierte Methoden
  \end{itemize}
\item
  Optimierung/Ausgleichsrechnung
\item
  Approximationstheorie

  \begin{itemize}
  \tightlist
  \item
    Universal Approximation Theorem
  \end{itemize}
\item
  Stabilität und Fehleranalyse

  \begin{itemize}
  \tightlist
  \item
    mixed precision Arithmetik
  \end{itemize}
\item
  Numerische lineare Algebra

  \begin{itemize}
  \tightlist
  \item
    PCA
  \item
    Support Vector Machines
  \item
    Empfehlungssysteme
  \end{itemize}
\item
  Automatisches Differenzieren

  \begin{itemize}
  \tightlist
  \item
    \emph{backward propagation} zur Gradientenberechnung
  \end{itemize}
\end{itemize}

\hypertarget{referenzen}{%
\chapter*{Referenzen}\label{referenzen}}
\addcontentsline{toc}{chapter}{Referenzen}

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-Byr14}{}%
Byrne, C.L.: Lecture notes on iterative optimization algorithms, \url{https://faculty.uml.edu/cbyrne/IOIPNotesOct2014.pdf}, (2014)

\leavevmode\hypertarget{ref-NocW06}{}%
Nocedal, J., Wright, S.J.: Numerical optimization. Springer (2006)

\leavevmode\hypertarget{ref-RicW17}{}%
Richter, T., Wick, T.: Einführung in die numerische Mathematik. Begriffe, Konzepte und zahlreiche Anwendungsbeispiele. Heidelberg: Springer Spektrum (2017)
\end{cslreferences}

\end{document}
